{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has apparently already been downloaded and unpacked.\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_1\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_2\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_3\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_4\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_5\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/test_batch\n"
     ]
    }
   ],
   "source": [
    "from utils import load_cifar10_data\n",
    "x_train, y_train, x_validate, y_validate, x_test, y_test = load_cifar10_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import network, train, utils\n",
    "from layers import ReluLayer, BinaryFullyConnectedLayer, \\\n",
    "    BinaryConvolutionLayer, BatchNormLayer, MaxPoolingLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = network.NeuralNetwork(in_size=[None, 32, 32, 3], n_out_classes=10, \n",
    "                           loss_func=utils.smooth_hinge_loss)\n",
    "nn.reset_graph()\n",
    "\n",
    "# Hidden Conv-1\n",
    "nn.add_layer(BinaryConvolutionLayer(\n",
    "    out_dim=128, filter_size=3))\n",
    "nn.add_layer(BatchNormLayer(axes=[0, 1, 2]))\n",
    "nn.add_layer(ReluLayer())\n",
    "\n",
    "# Hidden Conv-2\n",
    "nn.add_layer(BinaryConvolutionLayer(\n",
    "    out_dim=128, filter_size=3))\n",
    "nn.add_layer(MaxPoolingLayer())\n",
    "nn.add_layer(BatchNormLayer(axes=[0, 1, 2]))\n",
    "nn.add_layer(ReluLayer())\n",
    "\n",
    "# Hidden Conv-3\n",
    "nn.add_layer(BinaryConvolutionLayer(\n",
    "    out_dim=256, filter_size=3))\n",
    "nn.add_layer(BatchNormLayer(axes=[0, 1, 2]))\n",
    "nn.add_layer(ReluLayer())\n",
    "\n",
    "# Hidden Conv-4\n",
    "nn.add_layer(BinaryConvolutionLayer(\n",
    "    out_dim=256, filter_size=3))\n",
    "nn.add_layer(MaxPoolingLayer())\n",
    "nn.add_layer(BatchNormLayer(axes=[0, 1, 2]))\n",
    "nn.add_layer(ReluLayer())\n",
    "\n",
    "# Hidden Conv-5\n",
    "nn.add_layer(BinaryConvolutionLayer(\n",
    "    out_dim=512, filter_size=3))\n",
    "nn.add_layer(BatchNormLayer(axes=[0, 1, 2]))\n",
    "nn.add_layer(ReluLayer())\n",
    "\n",
    "# Hidden Conv-6\n",
    "nn.add_layer(BinaryConvolutionLayer(\n",
    "    out_dim=512, filter_size=3))\n",
    "nn.add_layer(MaxPoolingLayer())\n",
    "nn.add_layer(BatchNormLayer(axes=[0, 1, 2]))\n",
    "nn.add_layer(ReluLayer())\n",
    "\n",
    "# Hidden Fc-7\n",
    "nn.add_layer(BinaryFullyConnectedLayer(\n",
    "    out_dim=1024))\n",
    "nn.add_layer(BatchNormLayer(axes=[0]))\n",
    "nn.add_layer(ReluLayer())\n",
    "\n",
    "# Hidden Fc-8\n",
    "nn.add_layer(BinaryFullyConnectedLayer(\n",
    "    out_dim=1024))\n",
    "nn.add_layer(BatchNormLayer(axes=[0]))\n",
    "nn.add_layer(ReluLayer())\n",
    "\n",
    "# Hidden Fc-9\n",
    "nn.add_layer(BinaryFullyConnectedLayer(out_dim=10))\n",
    "nn.add_layer(BatchNormLayer(axes=[0]))\n",
    "\n",
    "nn.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = (x_train, y_train)\n",
    "opt = train.Trainer(nn, data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "opt.set_rho(0.5)\n",
    "opt.set_ema_rates(0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99900001, 0.99900001, 0.99900001, 0.99900001, 0.99900001, 0.99900001, 0.99900001, 0.99900001, 0.99900001]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 1.818457, 0.27\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 1.565276, 0.08\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 1.530898, 0.13\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 1.415289, 0.12\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 1.310719, 0.15\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 1.250380, 0.18\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 1.159019, 0.22\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 1.274668, 0.18\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 1.233475, 0.16\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 1.122713, 0.13\n",
      "Train loss/acc:  (1.1185676113764444, 0.19824444466167027) Test loss/acc:  (1.1222854328155518, 0.1994999998807907)\n",
      "Epoch:  1\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99902004, 0.99902004, 0.99902004, 0.99902004, 0.99902004, 0.99902004, 0.99902004, 0.99902004, 0.99902004]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 1.060849, 0.25\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.923462, 0.18\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.894373, 0.17\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.887329, 0.20\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.787772, 0.34\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.765217, 0.23\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.758335, 0.27\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.703594, 0.31\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.664784, 0.30\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.664967, 0.32\n",
      "Train loss/acc:  (0.72454749928580386, 0.27040000014834936) Test loss/acc:  (0.73631959915161138, 0.26650000035762789)\n",
      "Epoch:  2\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99903965, 0.99903965, 0.99903965, 0.99903965, 0.99903965, 0.99903965, 0.99903965, 0.99903965, 0.99903965]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.599899, 0.36\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.640335, 0.24\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.520659, 0.37\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.530456, 0.42\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.556666, 0.35\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.500215, 0.40\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.442367, 0.51\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.464307, 0.41\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.483133, 0.39\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.379526, 0.49\n",
      "Train loss/acc:  (0.45328013208177353, 0.42780000024371678) Test loss/acc:  (0.46805827498435976, 0.41910000205039977)\n",
      "Epoch:  3\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99905884, 0.99905884, 0.99905884, 0.99905884, 0.99905884, 0.99905884, 0.99905884, 0.99905884, 0.99905884]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.342410, 0.56\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.418908, 0.45\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.338443, 0.54\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.385101, 0.45\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.355431, 0.51\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.362359, 0.48\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.236500, 0.71\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.326699, 0.56\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.290694, 0.53\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.231233, 0.69\n",
      "Train loss/acc:  (0.35041984611087373, 0.46471111085679795) Test loss/acc:  (0.3709916663169861, 0.44359999418258667)\n",
      "Epoch:  4\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99907768, 0.99907768, 0.99907768, 0.99907768, 0.99907768, 0.99907768, 0.99907768, 0.99907768, 0.99907768]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.244606, 0.66\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.214675, 0.71\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.246080, 0.64\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.288402, 0.65\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.199105, 0.73\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.226062, 0.74\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.198432, 0.74\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.202997, 0.74\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.161914, 0.81\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.188286, 0.78\n",
      "Train loss/acc:  (0.24395830882920158, 0.63944444100062048) Test loss/acc:  (0.26098328888416289, 0.60680000543594359)\n",
      "Epoch:  5\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9990961, 0.9990961, 0.9990961, 0.9990961, 0.9990961, 0.9990961, 0.9990961, 0.9990961, 0.9990961]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.173392, 0.76\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.137894, 0.85\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.171448, 0.69\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.159660, 0.80\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.148817, 0.82\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.143987, 0.81\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.166970, 0.79\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.132190, 0.86\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.110873, 0.86\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.128497, 0.84\n",
      "Train loss/acc:  (0.21945161369111804, 0.66333333359824287) Test loss/acc:  (0.24636477947235108, 0.6261000013351441)\n",
      "Epoch:  6\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99911416, 0.99911416, 0.99911416, 0.99911416, 0.99911416, 0.99911416, 0.99911416, 0.99911416, 0.99911416]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.134550, 0.84\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.095914, 0.89\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.133802, 0.80\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.141615, 0.80\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.131196, 0.82\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.225423, 0.74\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.104232, 0.86\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.097893, 0.90\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.111575, 0.80\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.086595, 0.92\n",
      "Train loss/acc:  (0.16853969534238181, 0.75817777660157948) Test loss/acc:  (0.20279564678668976, 0.71439999341964722)\n",
      "Epoch:  7\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99913186, 0.99913186, 0.99913186, 0.99913186, 0.99913186, 0.99913186, 0.99913186, 0.99913186, 0.99913186]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.140819, 0.76\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.160607, 0.74\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.089914, 0.85\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.112346, 0.82\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.088860, 0.87\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.088587, 0.88\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.127951, 0.78\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.092111, 0.88\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.094512, 0.86\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.060504, 0.95\n",
      "Train loss/acc:  (0.11858235465155707, 0.81991110934151545) Test loss/acc:  (0.15610347211360931, 0.75269999504089358)\n",
      "Epoch:  8\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9991492, 0.9991492, 0.9991492, 0.9991492, 0.9991492, 0.9991492, 0.9991492, 0.9991492, 0.9991492]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.074205, 0.93\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.063161, 0.92\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.069550, 0.92\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.072844, 0.92\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.096571, 0.85\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.093774, 0.85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 270 of 450 || Estimated train loss/acc: 0.051172, 0.95\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.039138, 0.99\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.081427, 0.89\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.082112, 0.86\n",
      "Train loss/acc:  (0.13439599474271138, 0.77431110991371999) Test loss/acc:  (0.17235824823379517, 0.71359999656677242)\n",
      "Epoch:  9\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99916619, 0.99916619, 0.99916619, 0.99916619, 0.99916619, 0.99916619, 0.99916619, 0.99916619, 0.99916619]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.068084, 0.91\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.039982, 0.96\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.057007, 0.93\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.059276, 0.92\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.050742, 0.93\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.067744, 0.88\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.061446, 0.93\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.068665, 0.92\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.066022, 0.90\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.050186, 0.95\n",
      "Train loss/acc:  (0.14101311809486813, 0.7785777775446574) Test loss/acc:  (0.18009563088417052, 0.71089999437332152)\n",
      "Epoch:  10\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99918288, 0.99918288, 0.99918288, 0.99918288, 0.99918288, 0.99918288, 0.99918288, 0.99918288, 0.99918288]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.039540, 0.95\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.031015, 0.97\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.039341, 0.96\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.070373, 0.90\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.049367, 0.94\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.035846, 0.96\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.056167, 0.94\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.100832, 0.84\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.101616, 0.84\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.076399, 0.89\n",
      "Train loss/acc:  (0.092244844105508594, 0.85015555885103011) Test loss/acc:  (0.14544131159782409, 0.75529999971389772)\n",
      "Epoch:  11\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99919921, 0.99919921, 0.99919921, 0.99919921, 0.99919921, 0.99919921, 0.99919921, 0.99919921, 0.99919921]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.040714, 0.96\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.031437, 0.95\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.028117, 0.97\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.059526, 0.93\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.037900, 0.97\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.031605, 0.97\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.044489, 0.94\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.105262, 0.84\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.056104, 0.93\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.073609, 0.87\n",
      "Train loss/acc:  (0.094719937245051067, 0.85711111492580838) Test loss/acc:  (0.15116442561149598, 0.76039999485015874)\n",
      "Epoch:  12\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99921525, 0.99921525, 0.99921525, 0.99921525, 0.99921525, 0.99921525, 0.99921525, 0.99921525, 0.99921525]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.048239, 0.96\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.034879, 0.97\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.041898, 0.94\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.024360, 0.99\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.031386, 0.96\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.047048, 0.95\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.049480, 0.96\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.038897, 0.95\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.054453, 0.93\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.095145, 0.87\n",
      "Train loss/acc:  (0.090837164488103653, 0.85711111466089884) Test loss/acc:  (0.14191104650497435, 0.7594999957084656)\n",
      "Epoch:  13\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99923092, 0.99923092, 0.99923092, 0.99923092, 0.99923092, 0.99923092, 0.99923092, 0.99923092, 0.99923092]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.023814, 0.97\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.035047, 0.98\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.027160, 0.99\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.016816, 0.99\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.045403, 0.94\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.058123, 0.94\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.015443, 1.00\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.067865, 0.92\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.058375, 0.92\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.040729, 0.95\n",
      "Train loss/acc:  (0.098351928525500829, 0.84315555440055001) Test loss/acc:  (0.16076613426208497, 0.7421999931335449)\n",
      "Epoch:  14\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9992463, 0.9992463, 0.9992463, 0.9992463, 0.9992463, 0.9992463, 0.9992463, 0.9992463, 0.9992463]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.022043, 0.99\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.021926, 0.98\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.028062, 0.98\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.029009, 0.97\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.062163, 0.92\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.046207, 0.95\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.038840, 0.96\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.030350, 0.97\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.038467, 0.96\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.049614, 0.93\n",
      "Train loss/acc:  (0.07520926306645076, 0.88624444325764973) Test loss/acc:  (0.14626085668802261, 0.77079999446868896)\n",
      "Epoch:  15\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99926138, 0.99926138, 0.99926138, 0.99926138, 0.99926138, 0.99926138, 0.99926138, 0.99926138, 0.99926138]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.020204, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.011314, 1.00\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.019273, 1.00\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.031777, 0.96\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.015658, 0.99\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.023066, 1.00\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.042630, 0.96\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.051464, 0.94\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.045929, 0.96\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.023005, 0.97\n",
      "Train loss/acc:  (0.083418150941530864, 0.86555555846956045) Test loss/acc:  (0.1539405757188797, 0.74870000362396238)\n",
      "Epoch:  16\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99927616, 0.99927616, 0.99927616, 0.99927616, 0.99927616, 0.99927616, 0.99927616, 0.99927616, 0.99927616]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.010427, 0.99\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.018566, 1.00\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.030778, 0.98\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.024408, 0.97\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.024950, 0.97\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.036252, 0.97\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.017347, 0.99\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.017312, 0.99\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.021256, 1.00\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.042136, 0.96\n",
      "Train loss/acc:  (0.11540186299218072, 0.80584444496366714) Test loss/acc:  (0.17737026512622833, 0.71179999828338625)\n",
      "Epoch:  17\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99929065, 0.99929065, 0.99929065, 0.99929065, 0.99929065, 0.99929065, 0.99929065, 0.99929065, 0.99929065]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0 of 450 || Estimated train loss/acc: 0.036093, 0.96\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.015237, 1.00\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.035343, 0.96\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.013802, 0.99\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.014261, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.036864, 0.95\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.013270, 0.99\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.010993, 1.00\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.050563, 0.95\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.028884, 0.96\n",
      "Train loss/acc:  (0.075761164658599431, 0.88044444243113196) Test loss/acc:  (0.15148371040821076, 0.75919999837875363)\n",
      "Epoch:  18\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99930483, 0.99930483, 0.99930483, 0.99930483, 0.99930483, 0.99930483, 0.99930483, 0.99930483, 0.99930483]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.019246, 0.99\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.019183, 0.99\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.015365, 0.99\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.015276, 0.98\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.006952, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.011555, 1.00\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.016617, 1.00\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.004357, 1.00\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.003038, 1.00\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.027690, 0.96\n",
      "Train loss/acc:  (0.06507070773177677, 0.90042221705118819) Test loss/acc:  (0.13478521138429642, 0.78019999742507939)\n",
      "Epoch:  19\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99931872, 0.99931872, 0.99931872, 0.99931872, 0.99931872, 0.99931872, 0.99931872, 0.99931872, 0.99931872]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.015576, 0.98\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.025560, 0.98\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.017004, 0.98\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.008059, 0.99\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.013356, 0.99\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.014949, 1.00\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.012317, 0.99\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.012341, 1.00\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.009603, 1.00\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.052765, 0.95\n",
      "Train loss/acc:  (0.11591333130995432, 0.80604444662729902) Test loss/acc:  (0.19196658849716186, 0.69300000190734867)\n",
      "Epoch:  20\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99933237, 0.99933237, 0.99933237, 0.99933237, 0.99933237, 0.99933237, 0.99933237, 0.99933237, 0.99933237]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.015364, 0.99\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.014615, 0.98\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.018245, 0.98\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.023881, 0.96\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.007150, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.012738, 1.00\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.009631, 0.99\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.024204, 0.97\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.009317, 1.00\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.010931, 1.00\n",
      "Train loss/acc:  (0.054620427687962853, 0.91771111806233729) Test loss/acc:  (0.13394839644432069, 0.78319999933242801)\n",
      "Epoch:  21\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99934572, 0.99934572, 0.99934572, 0.99934572, 0.99934572, 0.99934572, 0.99934572, 0.99934572, 0.99934572]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.005744, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.029367, 0.95\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.009598, 1.00\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.010866, 1.00\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.009822, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.022798, 0.99\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.025478, 0.97\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.015266, 1.00\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.050264, 0.90\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.030867, 0.98\n",
      "Train loss/acc:  (0.049164032671186658, 0.93155555963516234) Test loss/acc:  (0.13374290227890015, 0.79590000629425051)\n",
      "Epoch:  22\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99935883, 0.99935883, 0.99935883, 0.99935883, 0.99935883, 0.99935883, 0.99935883, 0.99935883, 0.99935883]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.023989, 0.98\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.042861, 0.96\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.006557, 1.00\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.023284, 0.99\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.007510, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.006946, 1.00\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.035842, 0.96\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.012473, 0.99\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.028496, 0.97\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.016586, 0.98\n",
      "Train loss/acc:  (0.097354559666580617, 0.84037777927186752) Test loss/acc:  (0.17457511365413667, 0.72400000572204593)\n",
      "Epoch:  23\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99937165, 0.99937165, 0.99937165, 0.99937165, 0.99937165, 0.99937165, 0.99937165, 0.99937165, 0.99937165]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.032458, 0.97\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.025956, 0.98\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.005971, 1.00\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.051266, 0.93\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.011476, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.041159, 0.94\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.009536, 0.99\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.023556, 0.99\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.010757, 0.99\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.029383, 0.96\n",
      "Train loss/acc:  (0.060220362378491293, 0.90984444565243194) Test loss/acc:  (0.15386743664741517, 0.76519999265670779)\n",
      "Epoch:  24\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99938422, 0.99938422, 0.99938422, 0.99938422, 0.99938422, 0.99938422, 0.99938422, 0.99938422, 0.99938422]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.002949, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.015530, 1.00\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.015914, 0.99\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.014262, 0.99\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.001778, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.012590, 0.99\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.016501, 1.00\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.011606, 1.00\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.021584, 1.00\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.010348, 0.99\n",
      "Train loss/acc:  (0.040878770964013204, 0.94451110442479447) Test loss/acc:  (0.13127287358045578, 0.79710000038146978)\n",
      "Epoch:  25\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99939656, 0.99939656, 0.99939656, 0.99939656, 0.99939656, 0.99939656, 0.99939656, 0.99939656, 0.99939656]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.003777, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.008069, 1.00\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.023987, 0.99\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.006369, 1.00\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.004896, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.022229, 0.99\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.036400, 0.96\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.011054, 0.99\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.022970, 0.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 405 of 450 || Estimated train loss/acc: 0.013558, 0.99\n",
      "Train loss/acc:  (0.066336155467563204, 0.89339999251895486) Test loss/acc:  (0.15548272132873536, 0.75799999952316288)\n",
      "Epoch:  26\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9994086, 0.9994086, 0.9994086, 0.9994086, 0.9994086, 0.9994086, 0.9994086, 0.9994086, 0.9994086]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.013692, 0.98\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.030045, 0.97\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.002430, 1.00\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.008744, 1.00\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.002983, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.017184, 0.99\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.004569, 1.00\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.016420, 0.99\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.002267, 1.00\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.009887, 1.00\n",
      "Train loss/acc:  (0.065805556078751881, 0.89868888537089031) Test loss/acc:  (0.16360241591930388, 0.75589999914169315)\n",
      "Epoch:  27\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9994204, 0.9994204, 0.9994204, 0.9994204, 0.9994204, 0.9994204, 0.9994204, 0.9994204, 0.9994204]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.018972, 0.97\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.009073, 0.99\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.009303, 1.00\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.011266, 0.99\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.003017, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.013975, 1.00\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.028742, 0.97\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.032343, 0.95\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.026643, 0.96\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.028413, 0.98\n",
      "Train loss/acc:  (0.054419636097219254, 0.9210222294595507) Test loss/acc:  (0.15383323967456819, 0.77849999904632572)\n",
      "Epoch:  28\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99943197, 0.99943197, 0.99943197, 0.99943197, 0.99943197, 0.99943197, 0.99943197, 0.99943197, 0.99943197]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.003801, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.016744, 0.98\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.033484, 0.96\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.020614, 0.98\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.003862, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.006458, 1.00\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.016839, 1.00\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.051802, 0.91\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.037048, 0.96\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.034248, 0.96\n",
      "Train loss/acc:  (0.044080788393815358, 0.93533333539962771) Test loss/acc:  (0.14220843940973282, 0.78540000438690183)\n",
      "Epoch:  29\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99944335, 0.99944335, 0.99944335, 0.99944335, 0.99944335, 0.99944335, 0.99944335, 0.99944335, 0.99944335]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.010431, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.004827, 1.00\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.011637, 0.99\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.009848, 1.00\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.020046, 0.98\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.003933, 1.00\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.033500, 0.96\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.009639, 0.99\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.022043, 0.99\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.050508, 0.97\n",
      "Train loss/acc:  (0.032952417681614561, 0.95464443180296155) Test loss/acc:  (0.13197358846664428, 0.80929999828338628)\n",
      "Epoch:  30\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9994545, 0.9994545, 0.9994545, 0.9994545, 0.9994545, 0.9994545, 0.9994545, 0.9994545, 0.9994545]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.012515, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.003166, 1.00\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.003574, 1.00\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.004306, 1.00\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.005395, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.013026, 1.00\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.012187, 0.99\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.016110, 0.99\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.011841, 1.00\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.010248, 1.00\n",
      "Train loss/acc:  (0.05932887223031786, 0.90946666982438829) Test loss/acc:  (0.16316816776990892, 0.7584999990463257)\n",
      "Epoch:  31\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99946541, 0.99946541, 0.99946541, 0.99946541, 0.99946541, 0.99946541, 0.99946541, 0.99946541, 0.99946541]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.002174, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.005747, 1.00\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.001662, 1.00\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.016535, 0.99\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.008004, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.006928, 1.00\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.008961, 0.99\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.015860, 1.00\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.013036, 1.00\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.013656, 0.99\n",
      "Train loss/acc:  (0.040732082310650085, 0.94168888489405311) Test loss/acc:  (0.14450760841369628, 0.78520000696182246)\n",
      "Epoch:  32\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99947608, 0.99947608, 0.99947608, 0.99947608, 0.99947608, 0.99947608, 0.99947608, 0.99947608, 0.99947608]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.002889, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.021845, 0.97\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.007242, 0.99\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.006984, 1.00\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.001518, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.001867, 1.00\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.002242, 1.00\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.015841, 0.98\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.021597, 0.98\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.003820, 1.00\n",
      "Train loss/acc:  (0.033869433196054566, 0.95206665383444888) Test loss/acc:  (0.1398698279261589, 0.79360000610351566)\n",
      "Epoch:  33\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99948657, 0.99948657, 0.99948657, 0.99948657, 0.99948657, 0.99948657, 0.99948657, 0.99948657, 0.99948657]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.006710, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.001629, 1.00\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.008438, 1.00\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.009994, 1.00\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.008805, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.011968, 1.00\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.013305, 0.99\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.003692, 1.00\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.016459, 0.99\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.019288, 0.99\n",
      "Train loss/acc:  (0.037685563166936241, 0.94573332707087199) Test loss/acc:  (0.14109745264053344, 0.79400000095367429)\n",
      "Epoch:  34\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99949682, 0.99949682, 0.99949682, 0.99949682, 0.99949682, 0.99949682, 0.99949682, 0.99949682, 0.99949682]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.003575, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.006593, 1.00\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.009487, 0.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 135 of 450 || Estimated train loss/acc: 0.004994, 1.00\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.011477, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.014427, 0.99\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.004168, 1.00\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.003703, 1.00\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.017282, 0.98\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.006344, 1.00\n",
      "Train loss/acc:  (0.047056974702411228, 0.93117778168784249) Test loss/acc:  (0.15669322669506072, 0.77859999895095822)\n",
      "Epoch:  35\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99950689, 0.99950689, 0.99950689, 0.99950689, 0.99950689, 0.99950689, 0.99950689, 0.99950689, 0.99950689]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.003549, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.002741, 1.00\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.017374, 0.98\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.009811, 1.00\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.011694, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.011834, 0.99\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.002596, 1.00\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.007121, 1.00\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.014924, 0.99\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.007407, 1.00\n",
      "Train loss/acc:  (0.03172930179370774, 0.95764443318049108) Test loss/acc:  (0.14638604640960692, 0.79590000152587892)\n",
      "Epoch:  36\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99951673, 0.99951673, 0.99951673, 0.99951673, 0.99951673, 0.99951673, 0.99951673, 0.99951673, 0.99951673]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.011564, 0.99\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.002360, 1.00\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.012621, 0.99\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.017633, 0.99\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.000402, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.000901, 1.00\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.001644, 1.00\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.002669, 1.00\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.012708, 0.99\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.008053, 1.00\n",
      "Train loss/acc:  (0.027065265824397406, 0.96271110455195108) Test loss/acc:  (0.13800252526998519, 0.80880000591278078)\n",
      "Epoch:  37\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99952638, 0.99952638, 0.99952638, 0.99952638, 0.99952638, 0.99952638, 0.99952638, 0.99952638, 0.99952638]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.006151, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.003666, 1.00\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.004727, 1.00\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.018959, 0.98\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.004046, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.011727, 0.99\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.003144, 1.00\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.001422, 1.00\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.050088, 0.93\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.009209, 1.00\n",
      "Train loss/acc:  (0.045593766636318631, 0.9321555585331387) Test loss/acc:  (0.14386538714170455, 0.78419999837875365)\n",
      "Epoch:  38\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99953586, 0.99953586, 0.99953586, 0.99953586, 0.99953586, 0.99953586, 0.99953586, 0.99953586, 0.99953586]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.003105, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.002639, 1.00\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.012092, 1.00\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.006127, 1.00\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.010984, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.008005, 1.00\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.001485, 1.00\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.008112, 1.00\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.006623, 0.99\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.011531, 1.00\n",
      "Train loss/acc:  (0.035477585213051901, 0.94884443521499628) Test loss/acc:  (0.14686160951852797, 0.79269999980926509)\n",
      "Epoch:  39\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99954516, 0.99954516, 0.99954516, 0.99954516, 0.99954516, 0.99954516, 0.99954516, 0.99954516, 0.99954516]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.008286, 0.99\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.003218, 1.00\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.010284, 1.00\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.019181, 0.98\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.002612, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.009284, 1.00\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.007616, 1.00\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.001785, 1.00\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.010628, 1.00\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.012339, 0.98\n",
      "Train loss/acc:  (0.050064998583661188, 0.92575556092792088) Test loss/acc:  (0.16380944550037385, 0.76029999732971187)\n",
      "Epoch:  40\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99955428, 0.99955428, 0.99955428, 0.99955428, 0.99955428, 0.99955428, 0.99955428, 0.99955428, 0.99955428]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.001381, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.005252, 0.99\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.011105, 0.99\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.009630, 0.99\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.004937, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.001020, 1.00\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.007278, 1.00\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.010346, 1.00\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.004515, 1.00\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.020155, 0.98\n",
      "Train loss/acc:  (0.021767909286750688, 0.97226667430665759) Test loss/acc:  (0.13442399382591247, 0.80749999761581426)\n",
      "Epoch:  41\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99956322, 0.99956322, 0.99956322, 0.99956322, 0.99956322, 0.99956322, 0.99956322, 0.99956322, 0.99956322]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.002460, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.002452, 1.00\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.003460, 1.00\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.010399, 1.00\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.004017, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.003951, 1.00\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.006960, 1.00\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.007210, 1.00\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.012778, 0.99\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.003264, 1.00\n",
      "Train loss/acc:  (0.032411115053627225, 0.95284443378448491) Test loss/acc:  (0.14512164920568466, 0.79410000562667848)\n",
      "Epoch:  42\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99957198, 0.99957198, 0.99957198, 0.99957198, 0.99957198, 0.99957198, 0.99957198, 0.99957198, 0.99957198]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.001096, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.003455, 1.00\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.015355, 0.99\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.008314, 1.00\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.001537, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.001419, 1.00\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.002412, 1.00\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.014515, 0.99\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.006246, 1.00\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.009581, 0.99\n",
      "Train loss/acc:  (0.031374617185857559, 0.95602220932642623) Test loss/acc:  (0.14070561349391938, 0.79780000686645502)\n",
      "Epoch:  43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99958056, 0.99958056, 0.99958056, 0.99958056, 0.99958056, 0.99958056, 0.99958056, 0.99958056, 0.99958056]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.001344, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.014215, 0.98\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.008375, 1.00\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.005185, 1.00\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.001534, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.010794, 0.99\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.018244, 0.98\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.019843, 0.97\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.003739, 1.00\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.004734, 1.00\n",
      "Train loss/acc:  (0.024559243768453597, 0.96626666545867923) Test loss/acc:  (0.13643630087375641, 0.80300000667572025)\n",
      "Epoch:  44\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99958897, 0.99958897, 0.99958897, 0.99958897, 0.99958897, 0.99958897, 0.99958897, 0.99958897, 0.99958897]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.003190, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.003748, 1.00\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.003045, 1.00\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.000505, 1.00\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.019443, 0.97\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.026003, 0.96\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.005353, 1.00\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.019232, 0.98\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.002794, 1.00\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.001880, 1.00\n",
      "Train loss/acc:  (0.025917045432660313, 0.96393332613839044) Test loss/acc:  (0.14328429043293001, 0.80620000362396238)\n",
      "Epoch:  45\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99959719, 0.99959719, 0.99959719, 0.99959719, 0.99959719, 0.99959719, 0.99959719, 0.99959719, 0.99959719]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.001190, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.012109, 0.99\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.006127, 1.00\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.001930, 1.00\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.008245, 0.99\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.003423, 1.00\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.001298, 1.00\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.010205, 0.99\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.002264, 1.00\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.016434, 0.98\n",
      "Train loss/acc:  (0.021333925715751118, 0.9726000073220995) Test loss/acc:  (0.13569660186767579, 0.80620000123977664)\n",
      "Epoch:  46\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99960524, 0.99960524, 0.99960524, 0.99960524, 0.99960524, 0.99960524, 0.99960524, 0.99960524, 0.99960524]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.001713, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.000235, 1.00\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.015390, 0.99\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.026534, 0.97\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.007781, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.003471, 1.00\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.016828, 0.98\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.008034, 1.00\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.008330, 1.00\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.013881, 0.99\n",
      "Train loss/acc:  (0.034313896455698545, 0.9515777672661675) Test loss/acc:  (0.14556656539440155, 0.78880000114440918)\n",
      "Epoch:  47\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99961311, 0.99961311, 0.99961311, 0.99961311, 0.99961311, 0.99961311, 0.99961311, 0.99961311, 0.99961311]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.000597, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.001322, 1.00\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.012822, 0.98\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.004240, 1.00\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.010032, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.010794, 1.00\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.007096, 1.00\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.004207, 0.99\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.004981, 1.00\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.009911, 1.00\n",
      "Train loss/acc:  (0.028390885169307392, 0.96151110145780772) Test loss/acc:  (0.15249746620655061, 0.79270000457763667)\n",
      "Epoch:  48\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99962085, 0.99962085, 0.99962085, 0.99962085, 0.99962085, 0.99962085, 0.99962085, 0.99962085, 0.99962085]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.004074, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.021816, 0.97\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.001794, 1.00\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.010088, 1.00\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.000685, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.005522, 1.00\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.012466, 0.99\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.005824, 1.00\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.005626, 1.00\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.013769, 0.99\n",
      "Train loss/acc:  (0.023798172068264751, 0.96757777505450782) Test loss/acc:  (0.138738671541214, 0.80320000171661377)\n",
      "Epoch:  49\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99962842, 0.99962842, 0.99962842, 0.99962842, 0.99962842, 0.99962842, 0.99962842, 0.99962842, 0.99962842]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.007688, 0.99\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.002092, 1.00\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.006646, 1.00\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.007507, 0.99\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.002236, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.013896, 0.98\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.007736, 1.00\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.016266, 0.98\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.017927, 0.98\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.007064, 0.99\n",
      "Train loss/acc:  (0.022057225944267379, 0.97117778486675688) Test loss/acc:  (0.13752593100070953, 0.80779999732971186)\n",
      "Epoch:  50\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99963588, 0.99963588, 0.99963588, 0.99963588, 0.99963588, 0.99963588, 0.99963588, 0.99963588, 0.99963588]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.004166, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.004344, 1.00\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.002197, 1.00\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.002686, 1.00\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.007639, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.009683, 0.99\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.004505, 1.00\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.010883, 1.00\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.004040, 1.00\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.010503, 0.99\n",
      "Train loss/acc:  (0.038550321211417514, 0.94591110361946951) Test loss/acc:  (0.15766565322875978, 0.77969999551773073)\n",
      "Epoch:  51\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99964315, 0.99964315, 0.99964315, 0.99964315, 0.99964315, 0.99964315, 0.99964315, 0.99964315, 0.99964315]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.003810, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.002860, 1.00\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.021228, 0.99\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.007343, 1.00\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.000565, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.001797, 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 270 of 450 || Estimated train loss/acc: 0.008826, 1.00\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.009529, 1.00\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.002399, 1.00\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.002387, 1.00\n",
      "Train loss/acc:  (0.033976372480392453, 0.95282221025890779) Test loss/acc:  (0.14960452735424043, 0.79380000114440918)\n",
      "Epoch:  52\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9996503, 0.9996503, 0.9996503, 0.9996503, 0.9996503, 0.9996503, 0.9996503, 0.9996503, 0.9996503]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.000422, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.003159, 1.00\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.002257, 1.00\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.004842, 1.00\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.005422, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.003781, 1.00\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.007533, 1.00\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.010307, 1.00\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.009593, 1.00\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.002833, 1.00\n",
      "Train loss/acc:  (0.018219459553559622, 0.97615556610955134) Test loss/acc:  (0.13377153158187866, 0.81389999628067011)\n",
      "Epoch:  53\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99965727, 0.99965727, 0.99965727, 0.99965727, 0.99965727, 0.99965727, 0.99965727, 0.99965727, 0.99965727]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.004390, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.001494, 1.00\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.008750, 1.00\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.010833, 0.99\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.007477, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.007245, 1.00\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.015115, 0.98\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.013871, 0.99\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.018822, 0.98\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.004291, 1.00\n",
      "Train loss/acc:  (0.015983366784122256, 0.98057779312133786) Test loss/acc:  (0.13398960739374161, 0.81779999971389772)\n",
      "Epoch:  54\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99966413, 0.99966413, 0.99966413, 0.99966413, 0.99966413, 0.99966413, 0.99966413, 0.99966413, 0.99966413]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.000623, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.019749, 0.98\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.000200, 1.00\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.008453, 1.00\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.001307, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.011225, 0.98\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.001225, 1.00\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.005931, 1.00\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.003862, 1.00\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.016328, 0.99\n",
      "Train loss/acc:  (0.016347590088844299, 0.97813334729936385) Test loss/acc:  (0.13933992564678191, 0.81129999876022341)\n",
      "Epoch:  55\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99967086, 0.99967086, 0.99967086, 0.99967086, 0.99967086, 0.99967086, 0.99967086, 0.99967086, 0.99967086]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.021133, 0.97\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.002555, 1.00\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.002580, 1.00\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.000474, 1.00\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.011455, 0.99\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.002951, 1.00\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.002033, 1.00\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.011326, 0.99\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.004895, 1.00\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.005227, 1.00\n",
      "Train loss/acc:  (0.0321948733429114, 0.95346665514840023) Test loss/acc:  (0.15271106302738191, 0.78690000534057614)\n",
      "Epoch:  56\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99967742, 0.99967742, 0.99967742, 0.99967742, 0.99967742, 0.99967742, 0.99967742, 0.99967742, 0.99967742]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.006158, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.000241, 1.00\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.004077, 1.00\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.007364, 1.00\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.003100, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.016480, 0.96\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.006902, 1.00\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.008518, 1.00\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.009032, 0.99\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.011608, 0.99\n",
      "Train loss/acc:  (0.020588306792908243, 0.97444445398118762) Test loss/acc:  (0.14868335127830506, 0.8007000064849854)\n",
      "Epoch:  57\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99968386, 0.99968386, 0.99968386, 0.99968386, 0.99968386, 0.99968386, 0.99968386, 0.99968386, 0.99968386]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.000928, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.001511, 1.00\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.006118, 1.00\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.002704, 1.00\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.007080, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.001634, 1.00\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.015155, 0.97\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.012477, 0.98\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.000898, 1.00\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.008139, 1.00\n",
      "Train loss/acc:  (0.033673369147711331, 0.9509777673085531) Test loss/acc:  (0.16617837965488433, 0.78029999971389774)\n",
      "Epoch:  58\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99969018, 0.99969018, 0.99969018, 0.99969018, 0.99969018, 0.99969018, 0.99969018, 0.99969018, 0.99969018]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.003665, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.001116, 1.00\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.010481, 0.99\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.000635, 1.00\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.001975, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.001185, 1.00\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.004181, 0.99\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.001579, 1.00\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.002509, 1.00\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.003989, 1.00\n",
      "Train loss/acc:  (0.020663114363948503, 0.97317778640323216) Test loss/acc:  (0.14467301130294799, 0.80590000391006467)\n",
      "Epoch:  59\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99969637, 0.99969637, 0.99969637, 0.99969637, 0.99969637, 0.99969637, 0.99969637, 0.99969637, 0.99969637]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.000300, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.000311, 1.00\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.004300, 1.00\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.004518, 1.00\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.006108, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.004494, 1.00\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.000859, 1.00\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.008250, 1.00\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.009846, 0.98\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.002963, 1.00\n",
      "Train loss/acc:  (0.024165361813373035, 0.96797777705722388) Test loss/acc:  (0.15332945883274079, 0.80360000371932983)\n",
      "Epoch:  60\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99970245, 0.99970245, 0.99970245, 0.99970245, 0.99970245, 0.99970245, 0.99970245, 0.99970245, 0.99970245]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0 of 450 || Estimated train loss/acc: 0.000373, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.006256, 1.00\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.001693, 1.00\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.000037, 1.00\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.006548, 0.99\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.012431, 0.99\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.005109, 1.00\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.018476, 0.98\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.015300, 0.99\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.001548, 1.00\n",
      "Train loss/acc:  (0.020987736756602923, 0.97513334618674385) Test loss/acc:  (0.14719699829816818, 0.80560000419616695)\n",
      "Epoch:  61\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99970841, 0.99970841, 0.99970841, 0.99970841, 0.99970841, 0.99970841, 0.99970841, 0.99970841, 0.99970841]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.007762, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.000945, 1.00\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.001110, 1.00\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.009423, 1.00\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.010947, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.003798, 1.00\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.007831, 1.00\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.005396, 1.00\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.005625, 1.00\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.006790, 1.00\n",
      "Train loss/acc:  (0.025986527734332614, 0.9651777709854974) Test loss/acc:  (0.15938808202743529, 0.79250000715255742)\n",
      "Epoch:  62\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99971426, 0.99971426, 0.99971426, 0.99971426, 0.99971426, 0.99971426, 0.99971426, 0.99971426, 0.99971426]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.000285, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.000858, 1.00\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.000540, 1.00\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.000168, 1.00\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.000803, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.013449, 0.99\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.004223, 1.00\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.007507, 1.00\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.000950, 1.00\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.001218, 1.00\n",
      "Train loss/acc:  (0.017972933302323024, 0.975933346218533) Test loss/acc:  (0.15363670289516448, 0.80540000438690185)\n",
      "Epoch:  63\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99971998, 0.99971998, 0.99971998, 0.99971998, 0.99971998, 0.99971998, 0.99971998, 0.99971998, 0.99971998]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.004436, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.009177, 0.99\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.001831, 1.00\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.004098, 1.00\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.009569, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.006854, 1.00\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.009025, 1.00\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.001181, 1.00\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.002722, 1.00\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.001461, 1.00\n",
      "Train loss/acc:  (0.020889449467261633, 0.97246667702992762) Test loss/acc:  (0.14785531222820281, 0.7984000086784363)\n",
      "Epoch:  64\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99972558, 0.99972558, 0.99972558, 0.99972558, 0.99972558, 0.99972558, 0.99972558, 0.99972558, 0.99972558]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.000570, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.001482, 1.00\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.000652, 1.00\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.002990, 1.00\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.001027, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.000941, 1.00\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.000583, 1.00\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.009751, 1.00\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.004634, 1.00\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.010356, 0.99\n",
      "Train loss/acc:  (0.019749610556496513, 0.97553334448072648) Test loss/acc:  (0.1454501736164093, 0.80380000114440919)\n",
      "Epoch:  65\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99973106, 0.99973106, 0.99973106, 0.99973106, 0.99973106, 0.99973106, 0.99973106, 0.99973106, 0.99973106]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.000240, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.007067, 0.99\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.007713, 1.00\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.004160, 1.00\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.000857, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.000707, 1.00\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.013397, 1.00\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.001098, 1.00\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.007282, 1.00\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.010340, 0.99\n",
      "Train loss/acc:  (0.011571003215180503, 0.98628890196482344) Test loss/acc:  (0.13328142523765563, 0.82699999570846561)\n",
      "Epoch:  66\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99973643, 0.99973643, 0.99973643, 0.99973643, 0.99973643, 0.99973643, 0.99973643, 0.99973643, 0.99973643]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.000570, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.000257, 1.00\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.009643, 1.00\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.020651, 0.98\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.002843, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.001109, 1.00\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.011513, 1.00\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.001562, 1.00\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.000525, 1.00\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.000186, 1.00\n",
      "Train loss/acc:  (0.011471528911756144, 0.98593334621853301) Test loss/acc:  (0.13505500882863999, 0.81849999904632564)\n",
      "Epoch:  67\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99974167, 0.99974167, 0.99974167, 0.99974167, 0.99974167, 0.99974167, 0.99974167, 0.99974167, 0.99974167]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.000345, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.000504, 1.00\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.001035, 1.00\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.000733, 1.00\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.002349, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.001346, 1.00\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.000289, 1.00\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.009965, 0.99\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.007502, 1.00\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.015254, 0.99\n",
      "Train loss/acc:  (0.0096289544966485768, 0.98826667785644529) Test loss/acc:  (0.13989908456802369, 0.82129999876022342)\n",
      "Epoch:  68\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99974686, 0.99974686, 0.99974686, 0.99974686, 0.99974686, 0.99974686, 0.99974686, 0.99974686, 0.99974686]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.006318, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.006527, 0.99\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.000316, 1.00\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.000186, 1.00\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.003023, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.027199, 0.95\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.009709, 1.00\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.001811, 1.00\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.007331, 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 405 of 450 || Estimated train loss/acc: 0.015049, 0.99\n",
      "Train loss/acc:  (0.026806143911348449, 0.96288888427946306) Test loss/acc:  (0.15966088354587554, 0.7907000064849854)\n",
      "Epoch:  69\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99975193, 0.99975193, 0.99975193, 0.99975193, 0.99975193, 0.99975193, 0.99975193, 0.99975193, 0.99975193]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.002175, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.008701, 1.00\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.005069, 1.00\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.001342, 1.00\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.000916, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.001997, 1.00\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.000570, 1.00\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.010530, 0.99\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.003247, 1.00\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.005248, 1.00\n",
      "Train loss/acc:  (0.01077829639116923, 0.98748890082041418) Test loss/acc:  (0.13838137984275817, 0.82149999380111693)\n",
      "Epoch:  70\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99975687, 0.99975687, 0.99975687, 0.99975687, 0.99975687, 0.99975687, 0.99975687, 0.99975687, 0.99975687]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.000760, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.003271, 1.00\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.004811, 1.00\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.000159, 1.00\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.010194, 0.98\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.001066, 1.00\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.006162, 1.00\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.010299, 0.99\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.002477, 1.00\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.014262, 0.98\n",
      "Train loss/acc:  (0.010379071645438671, 0.98806667804718018) Test loss/acc:  (0.13487564384937287, 0.82090000152587894)\n",
      "Epoch:  71\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99976176, 0.99976176, 0.99976176, 0.99976176, 0.99976176, 0.99976176, 0.99976176, 0.99976176, 0.99976176]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.002820, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.000548, 1.00\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.003035, 1.00\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.003396, 1.00\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.000920, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.003734, 1.00\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.001586, 1.00\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.002621, 1.00\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.000519, 1.00\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.000537, 1.00\n",
      "Train loss/acc:  (0.016697311459316147, 0.97777779314253066) Test loss/acc:  (0.15152809500694275, 0.80740000247955324)\n",
      "Epoch:  72\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99976653, 0.99976653, 0.99976653, 0.99976653, 0.99976653, 0.99976653, 0.99976653, 0.99976653, 0.99976653]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.000332, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.001788, 1.00\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.001327, 1.00\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.000885, 1.00\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.003246, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.001542, 1.00\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.008532, 1.00\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.000129, 1.00\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.000215, 1.00\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.000606, 1.00\n",
      "Train loss/acc:  (0.021974501998888122, 0.96908888922797309) Test loss/acc:  (0.16485173225402833, 0.79749999761581425)\n",
      "Epoch:  73\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99977118, 0.99977118, 0.99977118, 0.99977118, 0.99977118, 0.99977118, 0.99977118, 0.99977118, 0.99977118]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.002244, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.000196, 1.00\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.000600, 1.00\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.002957, 1.00\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.005313, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.007885, 1.00\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.001084, 1.00\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.000106, 1.00\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.001484, 1.00\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.011700, 0.99\n",
      "Train loss/acc:  (0.022828422014911968, 0.97048889319101972) Test loss/acc:  (0.16981599807739259, 0.79470000267028806)\n",
      "Epoch:  74\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99977577, 0.99977577, 0.99977577, 0.99977577, 0.99977577, 0.99977577, 0.99977577, 0.99977577, 0.99977577]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.003188, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.000121, 1.00\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.002565, 1.00\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.000821, 1.00\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.008386, 0.99\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.002369, 1.00\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.013852, 0.98\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.000202, 1.00\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.005787, 1.00\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.001192, 1.00\n",
      "Train loss/acc:  (0.015533712771203783, 0.98015557183159718) Test loss/acc:  (0.15162229597568511, 0.81070000410079956)\n",
      "Epoch:  75\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99978024, 0.99978024, 0.99978024, 0.99978024, 0.99978024, 0.99978024, 0.99978024, 0.99978024, 0.99978024]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.012028, 0.98\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.000424, 1.00\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.000115, 1.00\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.000132, 1.00\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.001224, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.005949, 1.00\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.000060, 1.00\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.005688, 1.00\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.004603, 1.00\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.000972, 1.00\n",
      "Train loss/acc:  (0.0098189285480313835, 0.98908889929453536) Test loss/acc:  (0.13884400129318236, 0.81569999694824213)\n",
      "Epoch:  76\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99978465, 0.99978465, 0.99978465, 0.99978465, 0.99978465, 0.99978465, 0.99978465, 0.99978465, 0.99978465]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.008385, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.000987, 1.00\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.015354, 0.98\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.003256, 1.00\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.000391, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.002489, 1.00\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.006113, 1.00\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.009175, 0.99\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.004226, 1.00\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.008444, 0.98\n",
      "Train loss/acc:  (0.0077984387655225069, 0.99064445336659746) Test loss/acc:  (0.13819348812103271, 0.82389999866485597)\n",
      "Epoch:  77\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99978894, 0.99978894, 0.99978894, 0.99978894, 0.99978894, 0.99978894, 0.99978894, 0.99978894, 0.99978894]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.000729, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.003189, 1.00\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.018711, 0.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 135 of 450 || Estimated train loss/acc: 0.007163, 1.00\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.004321, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.001208, 1.00\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.000533, 1.00\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.005809, 1.00\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.000097, 1.00\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.000219, 1.00\n",
      "Train loss/acc:  (0.014448052330149544, 0.9818444612291124) Test loss/acc:  (0.15673400074243546, 0.81059999942779537)\n",
      "Epoch:  78\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99979317, 0.99979317, 0.99979317, 0.99979317, 0.99979317, 0.99979317, 0.99979317, 0.99979317, 0.99979317]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.000697, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.000404, 1.00\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.008877, 1.00\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.000263, 1.00\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.004990, 0.99\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.003591, 1.00\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.003382, 1.00\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.003780, 1.00\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.011208, 1.00\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.001540, 1.00\n",
      "Train loss/acc:  (0.014936033561825752, 0.98146668169233531) Test loss/acc:  (0.15997753620147706, 0.81089999914169308)\n",
      "Epoch:  79\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99979728, 0.99979728, 0.99979728, 0.99979728, 0.99979728, 0.99979728, 0.99979728, 0.99979728, 0.99979728]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.000325, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.003671, 1.00\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.000171, 1.00\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.001255, 1.00\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.006922, 0.99\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.006876, 1.00\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.001520, 1.00\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.000294, 1.00\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.019033, 0.98\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.000582, 1.00\n",
      "Train loss/acc:  (0.018416745720638169, 0.97691112412346737) Test loss/acc:  (0.16807778298854828, 0.79300000667572024)\n",
      "Epoch:  80\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99980134, 0.99980134, 0.99980134, 0.99980134, 0.99980134, 0.99980134, 0.99980134, 0.99980134, 0.99980134]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.001152, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.003550, 1.00\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.002933, 1.00\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.002109, 1.00\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.000077, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.001573, 1.00\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.005607, 1.00\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.005262, 1.00\n",
      "Iter: 360 of 450 || Estimated train loss/acc: 0.000994, 1.00\n",
      "Iter: 405 of 450 || Estimated train loss/acc: 0.001071, 1.00\n",
      "Train loss/acc:  (0.0081173008721735739, 0.99082223097483313) Test loss/acc:  (0.14435916960239412, 0.82599999666213986)\n",
      "Epoch:  81\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99980533, 0.99980533, 0.99980533, 0.99980533, 0.99980533, 0.99980533, 0.99980533, 0.99980533, 0.99980533]\n",
      "rho:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Iter: 0 of 450 || Estimated train loss/acc: 0.000526, 1.00\n",
      "Iter: 45 of 450 || Estimated train loss/acc: 0.003846, 1.00\n",
      "Iter: 90 of 450 || Estimated train loss/acc: 0.001933, 1.00\n",
      "Iter: 135 of 450 || Estimated train loss/acc: 0.001169, 1.00\n",
      "Iter: 180 of 450 || Estimated train loss/acc: 0.000875, 1.00\n",
      "Iter: 225 of 450 || Estimated train loss/acc: 0.000190, 1.00\n",
      "Iter: 270 of 450 || Estimated train loss/acc: 0.002966, 1.00\n",
      "Iter: 315 of 450 || Estimated train loss/acc: 0.005847, 1.00\n"
     ]
    }
   ],
   "source": [
    "losses_and_accs_train = []\n",
    "losses_and_accs_valid = []\n",
    "losses_and_accs_test = []\n",
    "\n",
    "n_epochs = 500\n",
    "\n",
    "for t in range(n_epochs):        \n",
    "    print('Epoch: ', t)\n",
    "\n",
    "    opt.train_epoch(batch_size=100, ema_decay=0.98, n_output=10, verbose=True)\n",
    "    losses_and_accs_train.append(\n",
    "        opt.loss_and_accuracy((x_train, y_train), max_batch=400, inference=True))\n",
    "    losses_and_accs_test.append(\n",
    "        opt.loss_and_accuracy((x_test, y_test), max_batch=400, inference=True))\n",
    "    losses_and_accs_valid.append(\n",
    "        opt.loss_and_accuracy((x_validate, y_validate), max_batch=400, inference=True))\n",
    "    \n",
    "    print('Train loss/acc: ', losses_and_accs_train[-1],\n",
    "          'Test loss/acc: ', losses_and_accs_test[-1])\n",
    "    \n",
    "losses_and_accs_train = np.asarray(losses_and_accs_train)\n",
    "losses_and_accs_valid = np.asarray(losses_and_accs_valid)\n",
    "losses_and_accs_test = np.asarray(losses_and_accs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  (0.0, 1.0)\n",
      "Valid:  (0.17338450193405153, 0.87519999980926511)\n",
      "Test:  (0.18636293739080428, 0.86809999704360963)\n"
     ]
    }
   ],
   "source": [
    "print('Train: ', opt.loss_and_accuracy((x_train, y_train), inference=True,\n",
    "                                       max_batch=400))\n",
    "print('Valid: ', opt.loss_and_accuracy((x_validate, y_validate), inference=True,\n",
    "                                      max_batch=400))\n",
    "print('Test: ', opt.loss_and_accuracy((x_test, y_test), inference=True,\n",
    "                                     max_batch=400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch:  326\n",
      "Train acc:  1.0\n",
      "Valid acc:  0.878599996567\n",
      "Test acc:  0.864900000095\n"
     ]
    }
   ],
   "source": [
    "best_epoch = np.argmax(losses_and_accs_valid[:,1]) + 1\n",
    "print('Best epoch: ', best_epoch)\n",
    "print('Train acc: ', losses_and_accs_train[best_epoch-1, 1])\n",
    "print('Valid acc: ', losses_and_accs_valid[best_epoch-1, 1])\n",
    "print('Test acc: ', losses_and_accs_test[best_epoch-1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results:  [ 0.          1.          0.1733845   0.8752      0.18636294  0.8681    ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0a040769e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save data\n",
    "losses_and_accs = np.concatenate(\n",
    "    [np.asarray(losses_and_accs_train),\n",
    "     np.asarray(losses_and_accs_valid),\n",
    "     np.asarray(losses_and_accs_test)], axis=1)\n",
    "\n",
    "# Plot\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,4))\n",
    "ax1.semilogy(losses_and_accs[:,0], '-o', label='Train loss')\n",
    "ax1.semilogy(losses_and_accs[:,2], '-o', label='Valid loss')\n",
    "ax1.semilogy(losses_and_accs[:,4], '-o', label='Test loss')\n",
    "\n",
    "ax2.plot(losses_and_accs[:,1], '-o', label='Train acc')\n",
    "ax2.plot(losses_and_accs[:,3], '-o', label='Valid acc')\n",
    "ax2.plot(losses_and_accs[:,5], '-o', label='Test acc')\n",
    "\n",
    "for ax in [ax1,ax2]:\n",
    "    ax.legend()\n",
    "\n",
    "ax2.set_ylim(0.1,1)\n",
    "    \n",
    "print('Final results: ', losses_and_accs[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
