{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_svhn_data\n",
    "x_train, y_train, x_validate, y_validate, x_test, y_test = load_svhn_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import network, train, utils\n",
    "from layers import ReluLayer, TernaryFullyConnectedLayer, \\\n",
    "    TernaryConvolutionLayer, BatchNormLayer, MaxPoolingLayer, DropOutLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = network.NeuralNetwork(in_size=[None, 32, 32, 3], n_out_classes=10,\n",
    "                           loss_func=utils.smooth_hinge_loss)\n",
    "nn.reset_graph()\n",
    "\n",
    "# Hidden Conv-1\n",
    "nn.add_layer(TernaryConvolutionLayer(\n",
    "    out_dim=64, filter_size=3))\n",
    "nn.add_layer(BatchNormLayer(axes=[0, 1, 2]))\n",
    "nn.add_layer(ReluLayer())\n",
    "\n",
    "# Hidden Conv-2\n",
    "nn.add_layer(TernaryConvolutionLayer(\n",
    "    out_dim=64, filter_size=3))\n",
    "nn.add_layer(MaxPoolingLayer())\n",
    "nn.add_layer(BatchNormLayer(axes=[0, 1, 2]))\n",
    "nn.add_layer(ReluLayer())\n",
    "\n",
    "# Hidden Conv-3\n",
    "nn.add_layer(TernaryConvolutionLayer(\n",
    "    out_dim=128, filter_size=3))\n",
    "nn.add_layer(BatchNormLayer(axes=[0, 1, 2]))\n",
    "nn.add_layer(ReluLayer())\n",
    "\n",
    "# Hidden Conv-4\n",
    "nn.add_layer(TernaryConvolutionLayer(\n",
    "    out_dim=128, filter_size=3))\n",
    "nn.add_layer(MaxPoolingLayer())\n",
    "nn.add_layer(BatchNormLayer(axes=[0, 1, 2]))\n",
    "nn.add_layer(ReluLayer())\n",
    "\n",
    "# Hidden Conv-5\n",
    "nn.add_layer(TernaryConvolutionLayer(\n",
    "    out_dim=256, filter_size=3))\n",
    "nn.add_layer(BatchNormLayer(axes=[0, 1, 2]))\n",
    "nn.add_layer(ReluLayer())\n",
    "\n",
    "# Hidden Conv-6\n",
    "nn.add_layer(TernaryConvolutionLayer(\n",
    "    out_dim=256, filter_size=3))\n",
    "nn.add_layer(MaxPoolingLayer())\n",
    "nn.add_layer(BatchNormLayer(axes=[0, 1, 2]))\n",
    "nn.add_layer(ReluLayer())\n",
    "\n",
    "# Hidden Fc-7\n",
    "nn.add_layer(TernaryFullyConnectedLayer(\n",
    "    out_dim=1024))\n",
    "nn.add_layer(BatchNormLayer(axes=[0]))\n",
    "nn.add_layer(ReluLayer())\n",
    "\n",
    "# Hidden Fc-8\n",
    "nn.add_layer(TernaryFullyConnectedLayer(\n",
    "    out_dim=1024))\n",
    "nn.add_layer(BatchNormLayer(axes=[0]))\n",
    "nn.add_layer(ReluLayer())\n",
    "\n",
    "# Hidden Fc-9\n",
    "nn.add_layer(TernaryFullyConnectedLayer(\n",
    "    out_dim=10))\n",
    "nn.add_layer(BatchNormLayer(axes=[0]))\n",
    "\n",
    "nn.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = (x_train, y_train)\n",
    "opt = train.Trainer(nn, data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.set_rho(0.25)\n",
    "opt.set_ema_rates(0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99900001, 0.99900001, 0.99900001, 0.99900001, 0.99900001, 0.99900001, 0.99900001, 0.99900001, 0.99900001]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 2.373887, 0.11\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 2.091202, 0.18\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 1.751957, 0.23\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 1.568507, 0.29\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 1.397124, 0.30\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 1.318553, 0.26\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 1.134544, 0.40\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 1.034272, 0.39\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.932190, 0.46\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.770082, 0.65\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.789119, 0.68\n",
      "Sparsity fraction (ratio of non-zero weights):  0.851542115767\n",
      "Train loss/acc:  (0.85505827538464885, 0.40142402990824877) Test loss/acc:  (0.85919961503626163, 0.38106945417157406)\n",
      "Epoch:  1\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99905002, 0.99905002, 0.99905002, 0.99905002, 0.99905002, 0.99905002, 0.99905002, 0.99905002, 0.99905002]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.743141, 0.62\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.747151, 0.59\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.706457, 0.67\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.533686, 0.80\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.598544, 0.72\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.477402, 0.79\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.489535, 0.75\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.428846, 0.76\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.393051, 0.84\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.396130, 0.76\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.266900, 0.90\n",
      "Sparsity fraction (ratio of non-zero weights):  0.742117328852\n",
      "Train loss/acc:  (0.31355801755375634, 0.85371463905733336) Test loss/acc:  (0.3327000374689964, 0.8258681569864359)\n",
      "Epoch:  2\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99909753, 0.99909753, 0.99909753, 0.99909753, 0.99909753, 0.99909753, 0.99909753, 0.99909753, 0.99909753]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.277748, 0.92\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.294870, 0.89\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.259654, 0.85\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.217344, 0.96\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.190848, 0.90\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.162454, 0.92\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.190856, 0.90\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.160669, 0.93\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.170623, 0.86\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.131899, 0.92\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.136435, 0.90\n",
      "Sparsity fraction (ratio of non-zero weights):  0.548434615853\n",
      "Train loss/acc:  (0.14335026854478986, 0.88273729906469589) Test loss/acc:  (0.15722854336530209, 0.86754763624605113)\n",
      "Epoch:  3\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99914265, 0.99914265, 0.99914265, 0.99914265, 0.99914265, 0.99914265, 0.99914265, 0.99914265, 0.99914265]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.123488, 0.92\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.102700, 0.95\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.139808, 0.86\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.122349, 0.90\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.160186, 0.87\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.107576, 0.90\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.098049, 0.92\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.093164, 0.91\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.067120, 0.96\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.099160, 0.90\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.093498, 0.90\n",
      "Sparsity fraction (ratio of non-zero weights):  0.25300989765\n",
      "Train loss/acc:  (0.072227412344085321, 0.92326062446509816) Test loss/acc:  (0.084470616086868691, 0.90903503347483605)\n",
      "Epoch:  4\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9991855, 0.9991855, 0.9991855, 0.9991855, 0.9991855, 0.9991855, 0.9991855, 0.9991855, 0.9991855]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.051142, 0.94\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.056266, 0.95\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.048289, 0.95\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.080120, 0.96\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.055458, 0.96\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.040278, 0.94\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.040672, 0.94\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.077534, 0.90\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.059844, 0.91\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.058514, 0.90\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.067063, 0.95\n",
      "Sparsity fraction (ratio of non-zero weights):  0.101804470652\n",
      "Train loss/acc:  (0.13933987032824527, 0.76235404187069489) Test loss/acc:  (0.15322465595652446, 0.74174093214661052)\n",
      "Epoch:  5\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99922621, 0.99922621, 0.99922621, 0.99922621, 0.99922621, 0.99922621, 0.99922621, 0.99922621, 0.99922621]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.031893, 0.97\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.042908, 0.93\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.038720, 0.96\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.116261, 0.87\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.043345, 0.97\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.051386, 0.93\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.073357, 0.86\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.019010, 0.99\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.061503, 0.90\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.042665, 0.96\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.048254, 0.92\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0999748576569\n",
      "Train loss/acc:  (0.050625207376709849, 0.92377339264044944) Test loss/acc:  (0.06147408538074968, 0.91164720703211755)\n",
      "Epoch:  6\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9992649, 0.9992649, 0.9992649, 0.9992649, 0.9992649, 0.9992649, 0.9992649, 0.9992649, 0.9992649]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.033410, 0.96\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.038139, 0.97\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.043663, 0.92\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.026466, 0.97\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.027264, 0.98\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.046724, 0.96\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.030958, 0.96\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.061448, 0.91\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.058905, 0.90\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.044452, 0.93\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.035973, 0.95\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0990267883077\n",
      "Train loss/acc:  (0.063670900100004771, 0.90639788329078219) Test loss/acc:  (0.070636640322871494, 0.89858635019948307)\n",
      "Epoch:  7\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99930167, 0.99930167, 0.99930167, 0.99930167, 0.99930167, 0.99930167, 0.99930167, 0.99930167, 0.99930167]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.337856, 0.87\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.019953, 0.99\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.027866, 0.97\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.030022, 0.94\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.021022, 0.99\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.055445, 0.91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 408 of 682 || Estimated train loss/acc: 0.035702, 0.95\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.023513, 0.98\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.015644, 0.99\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.065489, 0.92\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.021943, 0.98\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0913658695034\n",
      "Train loss/acc:  (0.057299989278431378, 0.91275620442958161) Test loss/acc:  (0.064821482050451823, 0.90373386432586744)\n",
      "Epoch:  8\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9993366, 0.9993366, 0.9993366, 0.9993366, 0.9993366, 0.9993366, 0.9993366, 0.9993366, 0.9993366]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.034414, 0.96\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.062683, 0.92\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.025782, 0.99\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.017758, 0.98\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.027878, 0.97\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.029083, 0.95\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.046808, 0.93\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.054558, 0.92\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.021571, 0.96\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.038314, 0.94\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.026286, 0.97\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0822237387445\n",
      "Train loss/acc:  (0.031839220084935796, 0.95383622658749234) Test loss/acc:  (0.046483402214280357, 0.93200676523254333)\n",
      "Epoch:  9\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99936974, 0.99936974, 0.99936974, 0.99936974, 0.99936974, 0.99936974, 0.99936974, 0.99936974, 0.99936974]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.026039, 0.96\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.030578, 0.94\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.019063, 0.98\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.020394, 0.98\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.021770, 0.99\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.040127, 0.95\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.030768, 0.96\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.046584, 0.94\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.014929, 0.99\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.023267, 0.97\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.024132, 0.98\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0823811516755\n",
      "Train loss/acc:  (0.037239972786778104, 0.94755115869698192) Test loss/acc:  (0.046895061164508221, 0.93185310746235717)\n",
      "Epoch:  10\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99940127, 0.99940127, 0.99940127, 0.99940127, 0.99940127, 0.99940127, 0.99940127, 0.99940127, 0.99940127]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.036482, 0.94\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.041710, 0.98\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.030796, 0.95\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.014069, 0.99\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.024431, 0.98\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.028049, 0.97\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.018052, 0.97\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.023719, 0.96\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.036104, 0.95\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.031248, 0.97\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.023805, 0.95\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0795784831515\n",
      "Train loss/acc:  (0.039836047889125079, 0.94087053025703371) Test loss/acc:  (0.052367028320630636, 0.92102029298666288)\n",
      "Epoch:  11\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99943119, 0.99943119, 0.99943119, 0.99943119, 0.99943119, 0.99943119, 0.99943119, 0.99943119, 0.99943119]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.037426, 0.95\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.024789, 0.96\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.024384, 0.97\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.030669, 0.94\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.009863, 0.99\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.017729, 0.98\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.018262, 0.99\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.033823, 0.93\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.039902, 0.96\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.026493, 0.96\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.041771, 0.94\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0796070610943\n",
      "Train loss/acc:  (0.032425927849965418, 0.95317695353542076) Test loss/acc:  (0.04607501756067868, 0.93269822124183432)\n",
      "Epoch:  12\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99945962, 0.99945962, 0.99945962, 0.99945962, 0.99945962, 0.99945962, 0.99945962, 0.99945962, 0.99945962]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.026832, 0.97\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.018097, 0.98\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.025414, 0.97\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.018121, 0.98\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.028021, 0.96\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.016000, 0.99\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.018378, 0.99\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.021061, 0.98\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.022262, 0.97\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.031806, 0.97\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.034257, 0.95\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0753427010685\n",
      "Train loss/acc:  (0.045904433721522864, 0.92903292387549707) Test loss/acc:  (0.054314661015468502, 0.91956054970173284)\n",
      "Epoch:  13\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99948663, 0.99948663, 0.99948663, 0.99948663, 0.99948663, 0.99948663, 0.99948663, 0.99948663, 0.99948663]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.016866, 0.98\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.014543, 0.99\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.022229, 0.97\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.026835, 0.95\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.023317, 0.98\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.032100, 0.95\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.009747, 0.99\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.011220, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.025742, 0.96\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.032403, 0.96\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.070078, 0.91\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0734865402574\n",
      "Train loss/acc:  (0.035890361597791777, 0.94634981705326227) Test loss/acc:  (0.05112584292906959, 0.92536109924023324)\n",
      "Epoch:  14\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99951231, 0.99951231, 0.99951231, 0.99951231, 0.99951231, 0.99951231, 0.99951231, 0.99951231, 0.99951231]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.034240, 0.93\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.027058, 0.96\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.020098, 0.97\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.018445, 0.97\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.025477, 0.97\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.019940, 0.98\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.038456, 0.94\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.023729, 0.98\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.052750, 0.92\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.021255, 0.98\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.017492, 0.97\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0734745156585\n",
      "Train loss/acc:  (0.024508098904087918, 0.96514642723438993) Test loss/acc:  (0.043153518814302766, 0.93642439993159055)\n",
      "Epoch:  15\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99953669, 0.99953669, 0.99953669, 0.99953669, 0.99953669, 0.99953669, 0.99953669, 0.99953669, 0.99953669]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.009461, 0.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 68 of 682 || Estimated train loss/acc: 0.014308, 0.99\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.013334, 0.98\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.021974, 0.96\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.010330, 0.98\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.041091, 0.94\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.018556, 0.98\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.025456, 0.98\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.020754, 0.97\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.028568, 0.98\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.014583, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0750238149524\n",
      "Train loss/acc:  (0.051680005024477033, 0.93741301192636795) Test loss/acc:  (0.068389288783439778, 0.91502766691253601)\n",
      "Epoch:  16\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99955988, 0.99955988, 0.99955988, 0.99955988, 0.99955988, 0.99955988, 0.99955988, 0.99955988, 0.99955988]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.012603, 0.99\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.045143, 0.94\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.025209, 0.96\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.013596, 0.98\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.018224, 0.98\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.004422, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.019999, 0.98\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.036233, 0.95\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.015404, 0.98\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.019998, 0.99\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.019276, 0.97\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0768556142384\n",
      "Train loss/acc:  (0.026289306315883297, 0.96240677884222425) Test loss/acc:  (0.04670869831978066, 0.93296712080100308)\n",
      "Epoch:  17\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99958187, 0.99958187, 0.99958187, 0.99958187, 0.99958187, 0.99958187, 0.99958187, 0.99958187, 0.99958187]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.012008, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.022516, 0.96\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.009486, 0.99\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.012635, 0.99\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.015817, 0.99\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.016422, 0.99\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.013561, 0.99\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.032342, 0.97\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.010180, 0.99\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.010410, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.016260, 0.98\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0755479000678\n",
      "Train loss/acc:  (0.021484546319555358, 0.97147545914919131) Test loss/acc:  (0.043091081872756454, 0.93992009702165502)\n",
      "Epoch:  18\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99960279, 0.99960279, 0.99960279, 0.99960279, 0.99960279, 0.99960279, 0.99960279, 0.99960279, 0.99960279]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.019759, 0.98\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.013847, 0.99\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.027940, 0.96\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.009131, 0.99\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.010736, 0.99\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.030102, 0.97\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.004324, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.012024, 0.99\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.025896, 0.97\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.010247, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.022686, 0.97\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0755652342298\n",
      "Train loss/acc:  (0.018753388214448746, 0.97428836180784206) Test loss/acc:  (0.039554443228680736, 0.94272433429242064)\n",
      "Epoch:  19\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99962264, 0.99962264, 0.99962264, 0.99962264, 0.99962264, 0.99962264, 0.99962264, 0.99962264, 0.99962264]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.016349, 0.97\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.016123, 0.98\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.010601, 0.99\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.012693, 0.98\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.002181, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.007574, 0.99\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.022652, 0.97\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.022116, 0.97\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.011428, 0.98\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.012709, 0.99\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.004672, 0.99\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0754916811639\n",
      "Train loss/acc:  (0.02292694760913852, 0.97050852275435073) Test loss/acc:  (0.04695102533745707, 0.93550246045423857)\n",
      "Epoch:  20\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99964154, 0.99964154, 0.99964154, 0.99964154, 0.99964154, 0.99964154, 0.99964154, 0.99964154, 0.99964154]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.024347, 0.97\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.012188, 0.98\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.005446, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.015807, 0.99\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.023933, 0.96\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.017859, 0.98\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.019229, 0.98\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.008514, 0.99\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.014291, 0.97\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.006644, 0.99\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.007845, 0.99\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0758888052546\n",
      "Train loss/acc:  (0.01739257800782339, 0.9766177952211863) Test loss/acc:  (0.042739264258328358, 0.9381530408706853)\n",
      "Epoch:  21\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99965948, 0.99965948, 0.99965948, 0.99965948, 0.99965948, 0.99965948, 0.99965948, 0.99965948, 0.99965948]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.009402, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.021368, 0.97\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.015873, 0.97\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.007509, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.015469, 0.98\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.026341, 0.96\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.028932, 0.95\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.017822, 0.97\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.018744, 0.98\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.008548, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.007818, 0.99\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0773926609344\n",
      "Train loss/acc:  (0.016535610779080744, 0.97702800986555738) Test loss/acc:  (0.04262102977329775, 0.94118776725125441)\n",
      "Epoch:  22\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99967653, 0.99967653, 0.99967653, 0.99967653, 0.99967653, 0.99967653, 0.99967653, 0.99967653, 0.99967653]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.014392, 0.99\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.005232, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.011956, 0.98\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.003944, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.002774, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.015053, 0.99\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.022910, 0.97\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.010052, 0.98\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.005322, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.020587, 0.98\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.034688, 0.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity fraction (ratio of non-zero weights):  0.0764762928005\n",
      "Train loss/acc:  (0.017137266821709681, 0.97547505287927294) Test loss/acc:  (0.045318237388507675, 0.93619391554766218)\n",
      "Epoch:  23\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99969268, 0.99969268, 0.99969268, 0.99969268, 0.99969268, 0.99969268, 0.99969268, 0.99969268, 0.99969268]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.018001, 0.98\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.006007, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.010779, 0.99\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.007802, 0.99\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.001743, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.024254, 0.96\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.017594, 0.96\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.018630, 0.97\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.014022, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.009593, 0.99\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.016724, 0.99\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0768712306006\n",
      "Train loss/acc:  (0.029364672702466271, 0.95584334658352488) Test loss/acc:  (0.055450997974199244, 0.91721727486102211)\n",
      "Epoch:  24\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99970806, 0.99970806, 0.99970806, 0.99970806, 0.99970806, 0.99970806, 0.99970806, 0.99970806, 0.99970806]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.020007, 0.98\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.003701, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.002795, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.002548, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.009832, 0.99\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.001294, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.017773, 0.98\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.012091, 0.98\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.012551, 0.97\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.005189, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.015973, 0.98\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0761111822523\n",
      "Train loss/acc:  (0.011336946384218146, 0.98540810245726873) Test loss/acc:  (0.041943820793303013, 0.94299323381495459)\n",
      "Epoch:  25\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99972266, 0.99972266, 0.99972266, 0.99972266, 0.99972266, 0.99972266, 0.99972266, 0.99972266, 0.99972266]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.007871, 0.99\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.014855, 0.99\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.008055, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.004479, 0.99\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.021725, 0.97\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.002280, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.012187, 0.99\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.010759, 0.99\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.007608, 0.99\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.027626, 0.96\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.014255, 0.98\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0770486324752\n",
      "Train loss/acc:  (0.011919047454279567, 0.98413350947503286) Test loss/acc:  (0.04195265098490375, 0.94337737519974052)\n",
      "Epoch:  26\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99973655, 0.99973655, 0.99973655, 0.99973655, 0.99973655, 0.99973655, 0.99973655, 0.99973655, 0.99973655]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.003733, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.018050, 0.99\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.007887, 0.99\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.006059, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.005306, 0.99\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.009503, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.009461, 0.99\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.005822, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.008513, 0.99\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.002711, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.012420, 0.97\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0763587015932\n",
      "Train loss/acc:  (0.010570651322179924, 0.9858329675997034) Test loss/acc:  (0.045270672893425255, 0.93880608360973983)\n",
      "Epoch:  27\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99974972, 0.99974972, 0.99974972, 0.99974972, 0.99974972, 0.99974972, 0.99974972, 0.99974972, 0.99974972]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000553, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.004366, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.003991, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.005077, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.007276, 0.99\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.003720, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.008522, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.009936, 0.98\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.004859, 0.99\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.017037, 0.97\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.009615, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0755065167079\n",
      "Train loss/acc:  (0.014722074030487666, 0.97926954065466054) Test loss/acc:  (0.05015308202828779, 0.93396589062883584)\n",
      "Epoch:  28\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99976224, 0.99976224, 0.99976224, 0.99976224, 0.99976224, 0.99976224, 0.99976224, 0.99976224, 0.99976224]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.005746, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.009117, 0.99\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000497, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.003559, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.007861, 0.99\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.005920, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.003178, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.004529, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.005960, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.008433, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.004197, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0751239158341\n",
      "Train loss/acc:  (0.0092022041485440749, 0.98908537885356362) Test loss/acc:  (0.04580690762223865, 0.94072679383079183)\n",
      "Epoch:  29\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9997741, 0.9997741, 0.9997741, 0.9997741, 0.9997741, 0.9997741, 0.9997741, 0.9997741, 0.9997741]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.002540, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.007616, 0.98\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.014096, 0.98\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.003624, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.011844, 0.98\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.002772, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.003815, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.009206, 0.99\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.011316, 0.99\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.006356, 0.99\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.010292, 0.98\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0744458533873\n",
      "Train loss/acc:  (0.0074716782137484805, 0.99084343831643285) Test loss/acc:  (0.044422758090611462, 0.94199446589212588)\n",
      "Epoch:  30\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99978542, 0.99978542, 0.99978542, 0.99978542, 0.99978542, 0.99978542, 0.99978542, 0.99978542, 0.99978542]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.004320, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.001591, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.003508, 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 204 of 682 || Estimated train loss/acc: 0.013810, 0.98\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.004964, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.010085, 0.99\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.009460, 0.99\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.003263, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.005983, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.011827, 0.98\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.007963, 0.99\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0747339752699\n",
      "Train loss/acc:  (0.0069950567327272447, 0.99164921604437994) Test loss/acc:  (0.044270063779639116, 0.94349261878382307)\n",
      "Epoch:  31\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99979615, 0.99979615, 0.99979615, 0.99979615, 0.99979615, 0.99979615, 0.99979615, 0.99979615, 0.99979615]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.001260, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.005668, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.002949, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.010714, 0.99\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.003087, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.003534, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.008265, 0.98\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.004323, 0.99\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.011707, 0.99\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.013443, 0.98\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.007203, 0.99\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0727928614485\n",
      "Train loss/acc:  (0.010988419019183017, 0.98464627693694817) Test loss/acc:  (0.051347829793026351, 0.93519514575646412)\n",
      "Epoch:  32\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99980634, 0.99980634, 0.99980634, 0.99980634, 0.99980634, 0.99980634, 0.99980634, 0.99980634, 0.99980634]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.004892, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.004056, 0.99\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.004827, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.004525, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.012104, 0.98\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000910, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.005453, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.013184, 0.98\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.005584, 0.99\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.003114, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.004897, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0712713592794\n",
      "Train loss/acc:  (0.006594340243653813, 0.99320216883911927) Test loss/acc:  (0.046039219650301964, 0.9441456614862429)\n",
      "Epoch:  33\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.999816, 0.999816, 0.999816, 0.999816, 0.999816, 0.999816, 0.999816, 0.999816, 0.999816]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.001592, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.003909, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.003095, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.003525, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.003722, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.005790, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.003933, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.002161, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.005623, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.008354, 0.98\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.011956, 0.99\n",
      "Sparsity fraction (ratio of non-zero weights):  0.070420892194\n",
      "Train loss/acc:  (0.0094430668586308244, 0.98766428060077671) Test loss/acc:  (0.054489734680486297, 0.93588660268162249)\n",
      "Epoch:  34\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99982518, 0.99982518, 0.99982518, 0.99982518, 0.99982518, 0.99982518, 0.99982518, 0.99982518, 0.99982518]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.004814, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.001287, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.006359, 0.99\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000997, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.003117, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.003837, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.002183, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.004636, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.007736, 0.99\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.002259, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.002656, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0698220047036\n",
      "Train loss/acc:  (0.0058485259560616459, 0.99293845987397489) Test loss/acc:  (0.051866408720264497, 0.93980485248507062)\n",
      "Epoch:  35\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99983394, 0.99983394, 0.99983394, 0.99983394, 0.99983394, 0.99983394, 0.99983394, 0.99983394, 0.99983394]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.006376, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.012088, 0.98\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.004829, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.005734, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.006509, 0.99\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.008874, 0.99\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000732, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.001835, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.005276, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.010111, 0.99\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.009832, 0.98\n",
      "Sparsity fraction (ratio of non-zero weights):  0.069444244902\n",
      "Train loss/acc:  (0.0089335123745117023, 0.98833820346716617) Test loss/acc:  (0.052549964904592822, 0.93488783105868978)\n",
      "Epoch:  36\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99984223, 0.99984223, 0.99984223, 0.99984223, 0.99984223, 0.99984223, 0.99984223, 0.99984223, 0.99984223]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.003124, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.001526, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.007073, 0.99\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.001968, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.002047, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.005140, 0.99\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.003842, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.018739, 0.97\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.008721, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.004403, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.006896, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0714083147759\n",
      "Train loss/acc:  (0.0057712483497478597, 0.99343657680813657) Test loss/acc:  (0.048757245492810623, 0.94107252366717198)\n",
      "Epoch:  37\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99985009, 0.99985009, 0.99985009, 0.99985009, 0.99985009, 0.99985009, 0.99985009, 0.99985009, 0.99985009]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.008278, 0.98\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.002559, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.002323, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.001533, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.009203, 0.99\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.002897, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000442, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.002950, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.002814, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000816, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.006016, 0.99\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0700757705894\n",
      "Train loss/acc:  (0.046297266327822391, 0.93269554908998265) Test loss/acc:  (0.083032666208118333, 0.89512906744206111)\n",
      "Epoch:  38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9998576, 0.9998576, 0.9998576, 0.9998576, 0.9998576, 0.9998576, 0.9998576, 0.9998576, 0.9998576]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.002711, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.005400, 0.99\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000163, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.009102, 0.99\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000857, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.001522, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.003023, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.004912, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.002297, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.006780, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.008726, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0669287612789\n",
      "Train loss/acc:  (0.0039304172429729398, 0.99610296751508809) Test loss/acc:  (0.053618467998471669, 0.94041948092811745)\n",
      "Epoch:  39\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9998647, 0.9998647, 0.9998647, 0.9998647, 0.9998647, 0.9998647, 0.9998647, 0.9998647, 0.9998647]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000679, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.001988, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.004406, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.002582, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.001065, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.007633, 0.99\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.001411, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.004276, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.002045, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000696, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000983, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0631169634296\n",
      "Train loss/acc:  (0.003126998674655654, 0.99718710435694791) Test loss/acc:  (0.052403569890079722, 0.94088045163761269)\n",
      "Epoch:  40\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99987149, 0.99987149, 0.99987149, 0.99987149, 0.99987149, 0.99987149, 0.99987149, 0.99987149, 0.99987149]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.001224, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.003430, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.007257, 0.99\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.003057, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.001797, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.001981, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.002409, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.003647, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000522, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.005602, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.003538, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0611783482261\n",
      "Train loss/acc:  (0.0076950621864358614, 0.99028671970962212) Test loss/acc:  (0.052561897681436438, 0.9379993840163664)\n",
      "Epoch:  41\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99987793, 0.99987793, 0.99987793, 0.99987793, 0.99987793, 0.99987793, 0.99987793, 0.99987793, 0.99987793]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000948, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.007082, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.007237, 0.99\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.004363, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.002752, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000474, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.002554, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.005490, 0.99\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.003403, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.006637, 0.99\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.006715, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0624093860583\n",
      "Train loss/acc:  (0.0051604616553018014, 0.9939346937719884) Test loss/acc:  (0.047810101974927251, 0.94637368548920198)\n",
      "Epoch:  42\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99988401, 0.99988401, 0.99988401, 0.99988401, 0.99988401, 0.99988401, 0.99988401, 0.99988401, 0.99988401]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.001760, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.001439, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.003864, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.001029, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.006058, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.002632, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.002729, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.007552, 0.99\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.001556, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.002167, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.005007, 0.99\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0616391870746\n",
      "Train loss/acc:  (0.002491574078080983, 0.99771452228723667) Test loss/acc:  (0.050051874698087639, 0.94852488287841896)\n",
      "Epoch:  43\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99988979, 0.99988979, 0.99988979, 0.99988979, 0.99988979, 0.99988979, 0.99988979, 0.99988979, 0.99988979]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.002166, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000715, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.001250, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.006607, 0.99\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000607, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.001307, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.001111, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.002929, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.001832, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.002100, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000301, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.059463515493\n",
      "Train loss/acc:  (0.00087412112594257825, 0.99953118406196551) Test loss/acc:  (0.051645164528533072, 0.94748770069621724)\n",
      "Epoch:  44\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99989527, 0.99989527, 0.99989527, 0.99989527, 0.99989527, 0.99989527, 0.99989527, 0.99989527, 0.99989527]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.001415, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000797, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000125, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000090, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.001541, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.001744, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000416, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000729, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000872, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.002179, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000626, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0568877527118\n",
      "Train loss/acc:  (0.00088239647650169869, 0.99942863057552045) Test loss/acc:  (0.051090100607259478, 0.94887061275143381)\n",
      "Epoch:  45\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99990052, 0.99990052, 0.99990052, 0.99990052, 0.99990052, 0.99990052, 0.99990052, 0.99990052, 0.99990052]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000614, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000028, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000692, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000973, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000240, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.002799, 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000743, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000907, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.001420, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000205, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.003084, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.053637987738\n",
      "Train loss/acc:  (0.00098572218979310839, 0.99938467908132966) Test loss/acc:  (0.054077497643396283, 0.94622002863488319)\n",
      "Epoch:  46\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99990547, 0.99990547, 0.99990547, 0.99990547, 0.99990547, 0.99990547, 0.99990547, 0.99990547, 0.99990547]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.001186, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.004468, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.001151, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.001377, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000209, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.001828, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000261, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000420, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000811, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000379, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000625, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0496297360522\n",
      "Train loss/acc:  (0.0010638988424026329, 0.9992967760929482) Test loss/acc:  (0.053067640968688295, 0.94683465616206264)\n",
      "Epoch:  47\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99991018, 0.99991018, 0.99991018, 0.99991018, 0.99991018, 0.99991018, 0.99991018, 0.99991018, 0.99991018]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.002618, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.002009, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.003055, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000491, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.001015, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.002474, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000425, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.001161, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.003842, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000644, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.003570, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0469284177189\n",
      "Train loss/acc:  (0.0064387997141736129, 0.99226453699274042) Test loss/acc:  (0.05527334690171843, 0.94126459382836192)\n",
      "Epoch:  48\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99991465, 0.99991465, 0.99991465, 0.99991465, 0.99991465, 0.99991465, 0.99991465, 0.99991465, 0.99991465]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.001480, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.004125, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.003373, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000747, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000317, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.001533, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.004692, 0.99\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.008242, 0.99\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.002737, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000943, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.003584, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0493561373865\n",
      "Train loss/acc:  (0.0050372910171008556, 0.99386144126682541) Test loss/acc:  (0.054119359809486282, 0.94137983653321178)\n",
      "Epoch:  49\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99991894, 0.99991894, 0.99991894, 0.99991894, 0.99991894, 0.99991894, 0.99991894, 0.99991894, 0.99991894]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000961, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.001014, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.002388, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.002096, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.002996, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.002028, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.005263, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.006409, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.002266, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.001954, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.002121, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0516136387061\n",
      "Train loss/acc:  (0.0039082638547503941, 0.99586855950153563) Test loss/acc:  (0.053184967512664397, 0.9410725227879394)\n",
      "Epoch:  50\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99992299, 0.99992299, 0.99992299, 0.99992299, 0.99992299, 0.99992299, 0.99992299, 0.99992299, 0.99992299]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.001559, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.005609, 0.98\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.003445, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.001845, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.004527, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.012247, 0.98\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.002406, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.004313, 0.99\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000619, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.002216, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.002024, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0523196544411\n",
      "Train loss/acc:  (0.0029786358821062434, 0.99708455088534786) Test loss/acc:  (0.052509116703792082, 0.94694990249374711)\n",
      "Epoch:  51\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99992687, 0.99992687, 0.99992687, 0.99992687, 0.99992687, 0.99992687, 0.99992687, 0.99992687, 0.99992687]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.001328, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.001946, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000656, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.002787, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000968, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.001675, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000716, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000998, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.009375, 0.99\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.001856, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.001103, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0517813584361\n",
      "Train loss/acc:  (0.0024996324927803321, 0.99730430835630157) Test loss/acc:  (0.051326948128178139, 0.94844805443294222)\n",
      "Epoch:  52\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999305, 0.9999305, 0.9999305, 0.9999305, 0.9999305, 0.9999305, 0.9999305, 0.9999305, 0.9999305]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.001483, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000278, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000039, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.002179, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000550, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.001083, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.002123, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.001749, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.001868, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.001674, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000781, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0507230375698\n",
      "Train loss/acc:  (0.0003868583422350462, 0.99988279601549135) Test loss/acc:  (0.050698451831771983, 0.95113705094049661)\n",
      "Epoch:  53\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99993396, 0.99993396, 0.99993396, 0.99993396, 0.99993396, 0.99993396, 0.99993396, 0.99993396, 0.99993396]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000499, 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 68 of 682 || Estimated train loss/acc: 0.002241, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000698, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000534, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000564, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000006, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000239, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.001372, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000421, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000263, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.001248, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0492233983078\n",
      "Train loss/acc:  (0.00048154833933417945, 0.99980954352517348) Test loss/acc:  (0.054899574768601862, 0.94744928647347881)\n",
      "Epoch:  54\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99993724, 0.99993724, 0.99993724, 0.99993724, 0.99993724, 0.99993724, 0.99993724, 0.99993724, 0.99993724]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000762, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000677, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000017, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000458, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.002534, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.001421, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000103, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000414, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.001346, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000386, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000064, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0479138101737\n",
      "Train loss/acc:  (0.0001898070211705716, 0.99997069900387281) Test loss/acc:  (0.052525478118679129, 0.94921634071944461)\n",
      "Epoch:  55\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999404, 0.9999404, 0.9999404, 0.9999404, 0.9999404, 0.9999404, 0.9999404, 0.9999404, 0.9999404]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000483, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000042, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000856, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000096, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000002, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000618, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000302, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000770, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000253, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000147, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000353, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0465931344225\n",
      "Train loss/acc:  (0.00034525927369335319, 0.99988279601549135) Test loss/acc:  (0.052958137339144742, 0.95040718254020184)\n",
      "Epoch:  56\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99994338, 0.99994338, 0.99994338, 0.99994338, 0.99994338, 0.99994338, 0.99994338, 0.99994338, 0.99994338]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000609, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000577, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000005, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000706, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000627, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000166, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000099, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.002129, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000415, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0451809467888\n",
      "Train loss/acc:  (8.8302754094586806e-05, 0.99995604850580921) Test loss/acc:  (0.052403686268194437, 0.95182850969738952)\n",
      "Epoch:  57\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99994624, 0.99994624, 0.99994624, 0.99994624, 0.99994624, 0.99994624, 0.99994624, 0.99994624, 0.99994624]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000067, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000068, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000056, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000199, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000828, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000006, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000321, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000130, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000833, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000019, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.001136, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0436196228961\n",
      "Train loss/acc:  (0.00010402762286230255, 0.9999853495019364) Test loss/acc:  (0.055560356154854704, 0.95098339588127767)\n",
      "Epoch:  58\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99994892, 0.99994892, 0.99994892, 0.99994892, 0.99994892, 0.99994892, 0.99994892, 0.99994892, 0.99994892]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000235, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000133, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000090, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000629, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000241, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000650, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.001042, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000560, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000048, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000118, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0417542484313\n",
      "Train loss/acc:  (0.00019891890861401933, 0.99992674750968213) Test loss/acc:  (0.056692938805175987, 0.9509833949654104)\n",
      "Epoch:  59\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99995148, 0.99995148, 0.99995148, 0.99995148, 0.99995148, 0.99995148, 0.99995148, 0.99995148, 0.99995148]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000020, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000030, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000120, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000025, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000156, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000706, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000305, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000030, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000193, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0399333805989\n",
      "Train loss/acc:  (0.00022759192873696512, 0.99991209701161854) Test loss/acc:  (0.055644266081821644, 0.95044559405197304)\n",
      "Epoch:  60\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99995393, 0.99995393, 0.99995393, 0.99995393, 0.99995393, 0.99995393, 0.99995393, 0.99995393, 0.99995393]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000071, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000101, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000055, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.001671, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000082, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000057, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000121, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.002894, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000342, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.001558, 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000264, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0379012233858\n",
      "Train loss/acc:  (0.00022244575875064932, 0.99991209701161854) Test loss/acc:  (0.059130985048252087, 0.94898585358791432)\n",
      "Epoch:  61\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99995625, 0.99995625, 0.99995625, 0.99995625, 0.99995625, 0.99995625, 0.99995625, 0.99995625, 0.99995625]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000090, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000299, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000235, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.001243, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000829, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000617, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.001479, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.001631, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000196, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000573, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.002907, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.03520755707\n",
      "Train loss/acc:  (0.00060888626439094219, 0.99961908705034697) Test loss/acc:  (0.061640817589586179, 0.9481023273807988)\n",
      "Epoch:  62\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99995846, 0.99995846, 0.99995846, 0.99995846, 0.99995846, 0.99995846, 0.99995846, 0.99995846, 0.99995846]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000241, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000491, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000357, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.002334, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.002355, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.001858, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.002751, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.006095, 0.99\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.004943, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.003709, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.007916, 0.99\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0327047227003\n",
      "Train loss/acc:  (0.0065987349660387613, 0.99189827454115098) Test loss/acc:  (0.063879881467448107, 0.93665488713639022)\n",
      "Epoch:  63\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99996054, 0.99996054, 0.99996054, 0.99996054, 0.99996054, 0.99996054, 0.99996054, 0.99996054, 0.99996054]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.001098, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.011055, 0.99\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.004083, 0.99\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.006326, 0.99\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.009768, 0.99\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.012861, 0.99\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.007269, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.014822, 0.98\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.013831, 0.97\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.018964, 0.98\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.006810, 0.99\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0360869144255\n",
      "Train loss/acc:  (0.0063487322673044157, 0.99241104198822128) Test loss/acc:  (0.053117683200828492, 0.94414566331797756)\n",
      "Epoch:  64\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99996251, 0.99996251, 0.99996251, 0.99996251, 0.99996251, 0.99996251, 0.99996251, 0.99996251, 0.99996251]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.003307, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000851, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.007069, 0.99\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000208, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.003153, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.003821, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000361, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.008263, 0.99\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.001998, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.011880, 0.98\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.001469, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0374118065945\n",
      "Train loss/acc:  (0.0013514117812095583, 0.99917957210843955) Test loss/acc:  (0.054793611532918646, 0.94668100293457835)\n",
      "Epoch:  65\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99996436, 0.99996436, 0.99996436, 0.99996436, 0.99996436, 0.99996436, 0.99996436, 0.99996436, 0.99996436]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.001420, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.003130, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000104, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.003613, 0.99\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.007323, 0.99\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000290, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000221, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000590, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.004028, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.011375, 0.99\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.002345, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0376843121149\n",
      "Train loss/acc:  (0.00064031391207624861, 0.9997655920309827) Test loss/acc:  (0.055686534764205084, 0.94741087225074039)\n",
      "Epoch:  66\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99996614, 0.99996614, 0.99996614, 0.99996614, 0.99996614, 0.99996614, 0.99996614, 0.99996614, 0.99996614]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.001322, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.002100, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.001256, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000593, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000535, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.003114, 0.99\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000304, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000245, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000490, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000245, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.001888, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0376063864675\n",
      "Train loss/acc:  (0.00035811234724717524, 0.99983884452130067) Test loss/acc:  (0.057043790796653726, 0.9481407424827698)\n",
      "Epoch:  67\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99996781, 0.99996781, 0.99996781, 0.99996781, 0.99996781, 0.99996781, 0.99996781, 0.99996781, 0.99996781]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000398, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.005701, 0.99\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000301, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000431, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000971, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.001238, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000006, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.001724, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000053, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000640, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0374133682307\n",
      "Train loss/acc:  (0.00013646511244147305, 0.99995604850580921) Test loss/acc:  (0.055694003587734062, 0.95036876831746353)\n",
      "Epoch:  68\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99996942, 0.99996942, 0.99996942, 0.99996942, 0.99996942, 0.99996942, 0.99996942, 0.99996942, 0.99996942]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000021, 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000190, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.001296, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000788, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000777, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.002138, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000342, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.001172, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.002585, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000499, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000156, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0371794351249\n",
      "Train loss/acc:  (9.4909778564756077e-05, 0.99997069900387281) Test loss/acc:  (0.056518983035208116, 0.95102181101988337)\n",
      "Epoch:  69\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99997097, 0.99997097, 0.99997097, 0.99997097, 0.99997097, 0.99997097, 0.99997097, 0.99997097, 0.99997097]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000388, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000043, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000351, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.001081, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000839, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000131, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000394, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000145, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000922, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000092, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000029, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0368288477936\n",
      "Train loss/acc:  (0.00010742205899346907, 0.99994139800774573) Test loss/acc:  (0.058685747695916182, 0.94944682697174221)\n",
      "Epoch:  70\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999724, 0.9999724, 0.9999724, 0.9999724, 0.9999724, 0.9999724, 0.9999724, 0.9999724, 0.9999724]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000152, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000147, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.001047, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000236, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000297, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000001, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000468, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000076, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000421, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000219, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.001735, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0364893480793\n",
      "Train loss/acc:  (6.1706220487214717e-05, 0.99997069900387281) Test loss/acc:  (0.059687348940142403, 0.95029194078785406)\n",
      "Epoch:  71\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99997377, 0.99997377, 0.99997377, 0.99997377, 0.99997377, 0.99997377, 0.99997377, 0.99997377, 0.99997377]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000807, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000203, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000648, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000036, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000824, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000741, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000203, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000146, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0361495360379\n",
      "Train loss/acc:  (5.4825759712179597e-05, 0.9999853495019364) Test loss/acc:  (0.060713214101412942, 0.95121388030184073)\n",
      "Epoch:  72\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99997509, 0.99997509, 0.99997509, 0.99997509, 0.99997509, 0.99997509, 0.99997509, 0.99997509, 0.99997509]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000363, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000180, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000050, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000033, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000350, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000029, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.001043, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000022, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000004, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.001042, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0358773428447\n",
      "Train loss/acc:  (3.9583074485918644e-05, 0.99997069900387281) Test loss/acc:  (0.060391122676757267, 0.95106022432675441)\n",
      "Epoch:  73\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99997634, 0.99997634, 0.99997634, 0.99997634, 0.99997634, 0.99997634, 0.99997634, 0.99997634, 0.99997634]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000070, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000249, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000339, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000059, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000179, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000158, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000008, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000227, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000424, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000008, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0355981222886\n",
      "Train loss/acc:  (3.1403589645899839e-05, 0.99997069900387281) Test loss/acc:  (0.061119402486306616, 0.95209741017242555)\n",
      "Epoch:  74\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99997753, 0.99997753, 0.99997753, 0.99997753, 0.99997753, 0.99997753, 0.99997753, 0.99997753, 0.99997753]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000030, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000167, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000050, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000021, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000015, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000096, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.001233, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.001087, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000037, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.003539, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000180, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0352806416451\n",
      "Train loss/acc:  (3.4719349543283584e-05, 0.99997069900387281) Test loss/acc:  (0.058923634625490488, 0.95186692300426057)\n",
      "Epoch:  75\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99997866, 0.99997866, 0.99997866, 0.99997866, 0.99997866, 0.99997866, 0.99997866, 0.99997866, 0.99997866]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000135, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000062, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000001, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000016, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.001132, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000014, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 680 of 682 || Estimated train loss/acc: 0.001255, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0348176165059\n",
      "Train loss/acc:  (0.00010658485390957773, 0.99995604850580921) Test loss/acc:  (0.061336442515638682, 0.95090656743580093)\n",
      "Epoch:  76\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99997973, 0.99997973, 0.99997973, 0.99997973, 0.99997973, 0.99997973, 0.99997973, 0.99997973, 0.99997973]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000516, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000088, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000080, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000959, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000306, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000288, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000081, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000265, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000338, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0343945692539\n",
      "Train loss/acc:  (4.1343919930083417e-05, 0.99997069900387281) Test loss/acc:  (0.061590477034275559, 0.95117546791083696)\n",
      "Epoch:  77\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99998075, 0.99998075, 0.99998075, 0.99998075, 0.99998075, 0.99998075, 0.99998075, 0.99998075, 0.99998075]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000286, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.002589, 0.99\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000075, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000602, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000096, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000374, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000027, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000240, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000173, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000022, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0341353376414\n",
      "Train loss/acc:  (3.5955362482889046e-05, 0.99997069900387281) Test loss/acc:  (0.061688705785377447, 0.95186692392012795)\n",
      "Epoch:  78\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999817, 0.9999817, 0.9999817, 0.9999817, 0.9999817, 0.9999817, 0.9999817, 0.9999817, 0.9999817]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000071, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.001000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000168, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000026, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000513, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000001, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000308, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000106, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000027, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000037, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0338834457191\n",
      "Train loss/acc:  (2.6534445302860419e-05, 0.99997069900387281) Test loss/acc:  (0.061581481018601086, 0.95236630885236162)\n",
      "Epoch:  79\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999826, 0.9999826, 0.9999826, 0.9999826, 0.9999826, 0.9999826, 0.9999826, 0.9999826, 0.9999826]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000085, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000242, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000727, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000050, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000076, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000001, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000079, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000918, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000308, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000009, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000422, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0335420720414\n",
      "Train loss/acc:  (4.057179738785813e-05, 0.99997069900387281) Test loss/acc:  (0.062482475024346347, 0.95167485192720336)\n",
      "Epoch:  80\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99998349, 0.99998349, 0.99998349, 0.99998349, 0.99998349, 0.99998349, 0.99998349, 0.99998349, 0.99998349]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000577, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000371, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000185, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000326, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000617, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000012, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000167, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.002058, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0332528570135\n",
      "Train loss/acc:  (2.6745971895103736e-05, 0.99997069900387281) Test loss/acc:  (0.063019706039920159, 0.95228948132275215)\n",
      "Epoch:  81\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99998432, 0.99998432, 0.99998432, 0.99998432, 0.99998432, 0.99998432, 0.99998432, 0.99998432, 0.99998432]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000015, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000044, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000178, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000779, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000396, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000097, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000184, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000415, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0327860839473\n",
      "Train loss/acc:  (3.864467238669859e-05, 0.99997069900387281) Test loss/acc:  (0.06543383174120794, 0.9503303540947251)\n",
      "Epoch:  82\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999851, 0.9999851, 0.9999851, 0.9999851, 0.9999851, 0.9999851, 0.9999851, 0.9999851, 0.9999851]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000180, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000019, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000161, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000043, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000144, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000231, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000025, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000014, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0324960881013\n",
      "Train loss/acc:  (3.1885605983904709e-05, 0.99997069900387281) Test loss/acc:  (0.06532317151435145, 0.95052242612428439)\n",
      "Epoch:  83\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99998581, 0.99998581, 0.99998581, 0.99998581, 0.99998581, 0.99998581, 0.99998581, 0.99998581, 0.99998581]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.001793, 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000001, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000399, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000051, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000118, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.001117, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000094, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000447, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000326, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000022, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0321103639549\n",
      "Train loss/acc:  (5.3278990736719417e-05, 0.99997069900387281) Test loss/acc:  (0.068446606660940643, 0.94971572565167828)\n",
      "Epoch:  84\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99998653, 0.99998653, 0.99998653, 0.99998653, 0.99998653, 0.99998653, 0.99998653, 0.99998653, 0.99998653]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000276, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000294, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000245, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000004, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000011, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000030, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000784, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000496, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000470, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0318180256546\n",
      "Train loss/acc:  (3.8111504471176504e-05, 0.99997069900387281) Test loss/acc:  (0.067349535275706321, 0.95148277989764407)\n",
      "Epoch:  85\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99998719, 0.99998719, 0.99998719, 0.99998719, 0.99998719, 0.99998719, 0.99998719, 0.99998719, 0.99998719]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000242, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000130, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.001223, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000066, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000249, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000546, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000079, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000481, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0314229316909\n",
      "Train loss/acc:  (3.5853330596410054e-05, 0.9999853495019364) Test loss/acc:  (0.068555942679896772, 0.95048401010644601)\n",
      "Epoch:  86\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99998784, 0.99998784, 0.99998784, 0.99998784, 0.99998784, 0.99998784, 0.99998784, 0.99998784, 0.99998784]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000161, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000347, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000079, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000031, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000010, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000051, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000754, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000037, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.031216327219\n",
      "Train loss/acc:  (2.6452937981327134e-05, 0.99997069900387281) Test loss/acc:  (0.067876522744116818, 0.95121388033847543)\n",
      "Epoch:  87\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99998844, 0.99998844, 0.99998844, 0.99998844, 0.99998844, 0.99998844, 0.99998844, 0.99998844, 0.99998844]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000139, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000192, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000015, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000025, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000088, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000846, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000020, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000415, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000156, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0310106597288\n",
      "Train loss/acc:  (2.2437470497751672e-05, 0.99997069900387281) Test loss/acc:  (0.070497000648138658, 0.95090656747243563)\n",
      "Epoch:  88\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99998903, 0.99998903, 0.99998903, 0.99998903, 0.99998903, 0.99998903, 0.99998903, 0.99998903, 0.99998903]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000023, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000425, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000001, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000040, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000437, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000021, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000239, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000135, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0308128004198\n",
      "Train loss/acc:  (2.2769760972793136e-05, 0.99997069900387281) Test loss/acc:  (0.069148794943083264, 0.9506760821360053)\n",
      "Epoch:  89\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99998957, 0.99998957, 0.99998957, 0.99998957, 0.99998957, 0.99998957, 0.99998957, 0.99998957, 0.99998957]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000039, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000293, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000067, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000020, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000004, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000074, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000074, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000174, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0306294643275\n",
      "Train loss/acc:  (2.1065097817215634e-05, 0.99997069900387281) Test loss/acc:  (0.070367281046966754, 0.95098339591791237)\n",
      "Epoch:  90\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99999011, 0.99999011, 0.99999011, 0.99999011, 0.99999011, 0.99999011, 0.99999011, 0.99999011, 0.99999011]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000400, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000166, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000113, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000537, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000033, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000031, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000494, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000029, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000022, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000294, 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity fraction (ratio of non-zero weights):  0.0302955865037\n",
      "Train loss/acc:  (2.53790969553075e-05, 0.99997069900387281) Test loss/acc:  (0.066948017224522913, 0.95159802622932854)\n",
      "Epoch:  91\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99999058, 0.99999058, 0.99999058, 0.99999058, 0.99999058, 0.99999058, 0.99999058, 0.99999058, 0.99999058]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000008, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.001918, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.001045, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000015, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000098, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000031, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000363, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000035, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0300947600858\n",
      "Train loss/acc:  (2.774845465867522e-05, 0.99997069900387281) Test loss/acc:  (0.068342297813055439, 0.95205899507045455)\n",
      "Epoch:  92\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99999106, 0.99999106, 0.99999106, 0.99999106, 0.99999106, 0.99999106, 0.99999106, 0.99999106, 0.99999106]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000061, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000435, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000065, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000060, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000003, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000156, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000648, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0299020541763\n",
      "Train loss/acc:  (2.1643051879890435e-05, 0.99997069900387281) Test loss/acc:  (0.068647230762390724, 0.95152119961558634)\n",
      "Epoch:  93\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99999154, 0.99999154, 0.99999154, 0.99999154, 0.99999154, 0.99999154, 0.99999154, 0.99999154, 0.99999154]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000046, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000064, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000031, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000363, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000002, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000015, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0297402686639\n",
      "Train loss/acc:  (2.7037513909325375e-05, 0.99997069900387281) Test loss/acc:  (0.069524968637138626, 0.95171326519743971)\n",
      "Epoch:  94\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99999195, 0.99999195, 0.99999195, 0.99999195, 0.99999195, 0.99999195, 0.99999195, 0.99999195, 0.99999195]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.002809, 0.99\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000263, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000409, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000507, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000073, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000161, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000085, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0295878529688\n",
      "Train loss/acc:  (2.2940074144178736e-05, 0.99997069900387281) Test loss/acc:  (0.070841332793364006, 0.95171326706580905)\n",
      "Epoch:  95\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99999237, 0.99999237, 0.99999237, 0.99999237, 0.99999237, 0.99999237, 0.99999237, 0.99999237, 0.99999237]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000045, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000012, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000001, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000010, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000105, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000250, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000004, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000119, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0294655768528\n",
      "Train loss/acc:  (1.7064211979974076e-05, 0.99997069900387281) Test loss/acc:  (0.070765549576879652, 0.95117546886333892)\n",
      "Epoch:  96\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99999273, 0.99999273, 0.99999273, 0.99999273, 0.99999273, 0.99999273, 0.99999273, 0.99999273, 0.99999273]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000024, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000052, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000063, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000144, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.001830, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000060, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0293026981951\n",
      "Train loss/acc:  (1.7837527494102305e-05, 0.99997069900387281) Test loss/acc:  (0.071223328420382911, 0.95182851064989149)\n",
      "Epoch:  97\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99999309, 0.99999309, 0.99999309, 0.99999309, 0.99999309, 0.99999309, 0.99999309, 0.99999309, 0.99999309]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000010, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.001143, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000304, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000191, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000042, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000070, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000295, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.029106088195\n",
      "Train loss/acc:  (1.9570706280680585e-05, 0.99997069900387281) Test loss/acc:  (0.072825689279756523, 0.95102181014065079)\n",
      "Epoch:  98\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99999344, 0.99999344, 0.99999344, 0.99999344, 0.99999344, 0.99999344, 0.99999344, 0.99999344, 0.99999344]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.001091, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000240, 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000015, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000030, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000202, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000077, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000618, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000452, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000001, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0289877161695\n",
      "Train loss/acc:  (2.0313174764825214e-05, 0.99997069900387281) Test loss/acc:  (0.072727471418316994, 0.95048401006981131)\n",
      "Epoch:  99\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999938, 0.9999938, 0.9999938, 0.9999938, 0.9999938, 0.9999938, 0.9999938, 0.9999938, 0.9999938]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000015, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000004, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000163, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000005, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000038, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000003, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000740, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000357, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000390, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0288374867651\n",
      "Train loss/acc:  (1.7226411433195216e-05, 0.99997069900387281) Test loss/acc:  (0.072767396791212455, 0.95071449632210903)\n",
      "Epoch:  100\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999941, 0.9999941, 0.9999941, 0.9999941, 0.9999941, 0.9999941, 0.9999941, 0.9999941, 0.9999941]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000004, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000245, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000110, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.002491, 0.99\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000128, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000001, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000001, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000530, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0287287968842\n",
      "Train loss/acc:  (1.5275259107259315e-05, 0.99997069900387281) Test loss/acc:  (0.072674675593318638, 0.95086815229719523)\n",
      "Epoch:  101\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999944, 0.9999944, 0.9999944, 0.9999944, 0.9999944, 0.9999944, 0.9999944, 0.9999944, 0.9999944]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000014, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000771, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.001153, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000067, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.028345102865\n",
      "Train loss/acc:  (7.4690206283080073e-05, 0.99994139800774573) Test loss/acc:  (0.076843189192362257, 0.94967731139230527)\n",
      "Epoch:  102\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999947, 0.9999947, 0.9999947, 0.9999947, 0.9999947, 0.9999947, 0.9999947, 0.9999947, 0.9999947]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000127, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000695, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000004, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000040, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000159, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000020, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0282298541119\n",
      "Train loss/acc:  (4.1567473632534082e-05, 0.99995604850580921) Test loss/acc:  (0.077172253688439024, 0.94894744116027585)\n",
      "Epoch:  103\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99999493, 0.99999493, 0.99999493, 0.99999493, 0.99999493, 0.99999493, 0.99999493, 0.99999493, 0.99999493]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000005, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000387, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000001, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000008, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000188, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000437, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0281453695924\n",
      "Train loss/acc:  (3.2223989291009131e-05, 0.99995604850580921) Test loss/acc:  (0.076609203247347712, 0.94971572653091096)\n",
      "Epoch:  104\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99999517, 0.99999517, 0.99999517, 0.99999517, 0.99999517, 0.99999517, 0.99999517, 0.99999517, 0.99999517]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000251, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000030, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000079, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000012, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000689, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0280419892747\n",
      "Train loss/acc:  (2.7109966555582896e-05, 0.99997069900387281) Test loss/acc:  (0.076755631329250174, 0.9503303540947251)\n",
      "Epoch:  105\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99999541, 0.99999541, 0.99999541, 0.99999541, 0.99999541, 0.99999541, 0.99999541, 0.99999541, 0.99999541]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000074, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000240, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000934, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000107, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000003, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0279417322294\n",
      "Train loss/acc:  (2.0203280616671985e-05, 0.99997069900387281) Test loss/acc:  (0.076278481426400938, 0.95021511051064267)\n",
      "Epoch:  106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99999565, 0.99999565, 0.99999565, 0.99999565, 0.99999565, 0.99999565, 0.99999565, 0.99999565, 0.99999565]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000548, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.003135, 0.99\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000180, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000467, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0278389765661\n",
      "Train loss/acc:  (1.6198388316108635e-05, 0.99997069900387281) Test loss/acc:  (0.076016686830415486, 0.94998462517421234)\n",
      "Epoch:  107\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99999589, 0.99999589, 0.99999589, 0.99999589, 0.99999589, 0.99999589, 0.99999589, 0.99999589, 0.99999589]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000161, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000406, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000002, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000011, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000258, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000152, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000267, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0277452783929\n",
      "Train loss/acc:  (1.7346550678770893e-05, 0.99997069900387281) Test loss/acc:  (0.077631671757843135, 0.94960048203096115)\n",
      "Epoch:  108\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99999607, 0.99999607, 0.99999607, 0.99999607, 0.99999607, 0.99999607, 0.99999607, 0.99999607, 0.99999607]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000056, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.001190, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000001, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000024, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000172, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000046, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000033, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000238, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0276428350569\n",
      "Train loss/acc:  (1.7141484206380206e-05, 0.99997069900387281) Test loss/acc:  (0.075964252834827092, 0.95036876831746353)\n",
      "Epoch:  109\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99999624, 0.99999624, 0.99999624, 0.99999624, 0.99999624, 0.99999624, 0.99999624, 0.99999624, 0.99999624]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000024, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000001, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000094, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000051, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000067, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000495, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000007, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000283, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0275641285914\n",
      "Train loss/acc:  (1.5982968352800852e-05, 0.9999853495019364) Test loss/acc:  (0.078026838735725954, 0.94971572561504358)\n",
      "Epoch:  110\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99999642, 0.99999642, 0.99999642, 0.99999642, 0.99999642, 0.99999642, 0.99999642, 0.99999642, 0.99999642]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000260, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000007, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000146, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0275013508153\n",
      "Train loss/acc:  (1.4193177256359333e-05, 0.9999853495019364) Test loss/acc:  (0.076952634765076799, 0.95048400915394404)\n",
      "Epoch:  111\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999966, 0.9999966, 0.9999966, 0.9999966, 0.9999966, 0.9999966, 0.9999966, 0.9999966, 0.9999966]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000311, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000042, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000014, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000141, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000082, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000573, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000001, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.027432482658\n",
      "Train loss/acc:  (1.5873267666300127e-05, 0.99997069900387281) Test loss/acc:  (0.077487303946938854, 0.95052242520841701)\n",
      "Epoch:  112\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99999678, 0.99999678, 0.99999678, 0.99999678, 0.99999678, 0.99999678, 0.99999678, 0.99999678, 0.99999678]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000001, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000008, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000048, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000021, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0273773568995\n",
      "Train loss/acc:  (1.3984676342606573e-05, 0.99997069900387281) Test loss/acc:  (0.079750170895730194, 0.95017669537203697)\n",
      "Epoch:  113\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99999696, 0.99999696, 0.99999696, 0.99999696, 0.99999696, 0.99999696, 0.99999696, 0.99999696, 0.99999696]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000006, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000001, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000149, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000071, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000075, 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000002, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000038, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0273094257239\n",
      "Train loss/acc:  (1.8730073230705413e-05, 0.99997069900387281) Test loss/acc:  (0.078985109809641837, 0.95006145545142373)\n",
      "Epoch:  114\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99999714, 0.99999714, 0.99999714, 0.99999714, 0.99999714, 0.99999714, 0.99999714, 0.99999714, 0.99999714]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000042, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000009, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000130, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000001, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0272621081464\n",
      "Train loss/acc:  (1.3169468958324119e-05, 0.99997069900387281) Test loss/acc:  (0.078762423019276925, 0.9504071807084673)\n",
      "Epoch:  115\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99999726, 0.99999726, 0.99999726, 0.99999726, 0.99999726, 0.99999726, 0.99999726, 0.99999726, 0.99999726]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000115, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000158, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000220, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000027, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000182, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.027139988194\n",
      "Train loss/acc:  (5.2911578099397734e-05, 0.99997069900387281) Test loss/acc:  (0.081735652037418241, 0.94860171223976308)\n",
      "Epoch:  116\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99999738, 0.99999738, 0.99999738, 0.99999738, 0.99999738, 0.99999738, 0.99999738, 0.99999738, 0.99999738]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000205, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000147, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000418, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000102, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000066, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000055, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000045, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0270214600049\n",
      "Train loss/acc:  (3.1209068932612086e-05, 0.99997069900387281) Test loss/acc:  (0.080856642813479596, 0.94925475402631565)\n",
      "Epoch:  117\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999975, 0.9999975, 0.9999975, 0.9999975, 0.9999975, 0.9999975, 0.9999975, 0.9999975, 0.9999975]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000069, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000686, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000098, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000058, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000028, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0269638356284\n",
      "Train loss/acc:  (1.4570469708613201e-05, 0.99997069900387281) Test loss/acc:  (0.078770349441026358, 0.9501766981196389)\n",
      "Epoch:  118\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99999762, 0.99999762, 0.99999762, 0.99999762, 0.99999762, 0.99999762, 0.99999762, 0.99999762, 0.99999762]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000093, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000242, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000045, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0269149564147\n",
      "Train loss/acc:  (1.375942221909425e-05, 0.99997069900387281) Test loss/acc:  (0.080663713887013322, 0.95059925273802648)\n",
      "Epoch:  119\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99999774, 0.99999774, 0.99999774, 0.99999774, 0.99999774, 0.99999774, 0.99999774, 0.99999774, 0.99999774]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000014, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000439, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000110, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000220, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000010, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000983, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.026868575819\n",
      "Train loss/acc:  (1.3947858212778789e-05, 0.99997069900387281) Test loss/acc:  (0.081874620154518324, 0.95021511142650994)\n",
      "Epoch:  120\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99999785, 0.99999785, 0.99999785, 0.99999785, 0.99999785, 0.99999785, 0.99999785, 0.99999785, 0.99999785]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000002, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.002331, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000009, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000166, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000070, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000714, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.02682766095\n",
      "Train loss/acc:  (1.3009624355431725e-05, 0.9999853495019364) Test loss/acc:  (0.080260766904798844, 0.9507913238517185)\n",
      "Epoch:  121\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99999797, 0.99999797, 0.99999797, 0.99999797, 0.99999797, 0.99999797, 0.99999797, 0.99999797, 0.99999797]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000012, 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000026, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000072, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000221, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000171, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000010, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0267976775346\n",
      "Train loss/acc:  (1.3160571434762348e-05, 0.99997069900387281) Test loss/acc:  (0.079900270750369484, 0.95048401281741324)\n",
      "Epoch:  122\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99999809, 0.99999809, 0.99999809, 0.99999809, 0.99999809, 0.99999809, 0.99999809, 0.99999809, 0.99999809]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000009, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000119, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000099, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000001, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000011, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000002, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000121, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000099, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0267701927371\n",
      "Train loss/acc:  (1.5994693814589189e-05, 0.99997069900387281) Test loss/acc:  (0.08025705059572423, 0.95082973807445681)\n",
      "Epoch:  123\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99999821, 0.99999821, 0.99999821, 0.99999821, 0.99999821, 0.99999821, 0.99999821, 0.99999821, 0.99999821]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000062, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000030, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000001, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000056, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000133, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000058, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0267541078841\n",
      "Train loss/acc:  (1.4595165576788871e-05, 0.99997069900387281) Test loss/acc:  (0.083133947183209184, 0.94998462425834496)\n",
      "Epoch:  124\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99999833, 0.99999833, 0.99999833, 0.99999833, 0.99999833, 0.99999833, 0.99999833, 0.99999833, 0.99999833]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000083, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000447, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000018, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000001, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000089, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0267253737776\n",
      "Train loss/acc:  (1.5447417603989075e-05, 0.99997069900387281) Test loss/acc:  (0.082396678094189449, 0.94979255406052043)\n",
      "Epoch:  125\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99999839, 0.99999839, 0.99999839, 0.99999839, 0.99999839, 0.99999839, 0.99999839, 0.99999839, 0.99999839]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000075, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000809, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000077, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000097, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.002245, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000075, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000059, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0266907054535\n",
      "Train loss/acc:  (1.4681990855396561e-05, 0.9999853495019364) Test loss/acc:  (0.080000571229969647, 0.95063766879249956)\n",
      "Epoch:  126\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99999845, 0.99999845, 0.99999845, 0.99999845, 0.99999845, 0.99999845, 0.99999845, 0.99999845, 0.99999845]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000090, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000005, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000366, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000034, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000606, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0266660316013\n",
      "Train loss/acc:  (1.5285499845186377e-05, 0.99997069900387281) Test loss/acc:  (0.080209255334134102, 0.95048401006981131)\n",
      "Epoch:  127\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99999851, 0.99999851, 0.99999851, 0.99999851, 0.99999851, 0.99999851, 0.99999851, 0.99999851, 0.99999851]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000010, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000168, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000021, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000004, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000054, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000786, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0266502590754\n",
      "Train loss/acc:  (1.2680212325158453e-05, 0.99997069900387281) Test loss/acc:  (0.083229811451115632, 0.9507144972379763)\n",
      "Epoch:  128\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99999857, 0.99999857, 0.99999857, 0.99999857, 0.99999857, 0.99999857, 0.99999857, 0.99999857, 0.99999857]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000009, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000002, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000139, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000810, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000081, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000449, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.026621524969\n",
      "Train loss/acc:  (1.2896356491734688e-05, 0.99997069900387281) Test loss/acc:  (0.081330054743557742, 0.95025352381751371)\n",
      "Epoch:  129\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99999863, 0.99999863, 0.99999863, 0.99999863, 0.99999863, 0.99999863, 0.99999863, 0.99999863, 0.99999863]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000014, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000081, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000005, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000286, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000011, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0265423500126\n",
      "Train loss/acc:  (1.4735676356536738e-05, 0.99997069900387281) Test loss/acc:  (0.082703538252740239, 0.94990779581286822)\n",
      "Epoch:  130\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99999869, 0.99999869, 0.99999869, 0.99999869, 0.99999869, 0.99999869, 0.99999869, 0.99999869, 0.99999869]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000009, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000041, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000157, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000008, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000232, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0265111172882\n",
      "Train loss/acc:  (1.288974354396284e-05, 0.99997069900387281) Test loss/acc:  (0.082976114854317315, 0.94971572561504358)\n",
      "Epoch:  131\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99999875, 0.99999875, 0.99999875, 0.99999875, 0.99999875, 0.99999875, 0.99999875, 0.99999875, 0.99999875]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000017, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000010, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000501, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000043, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000017, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000408, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000138, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0264831639999\n",
      "Train loss/acc:  (1.3007085595819089e-05, 0.99997069900387281) Test loss/acc:  (0.0842234748687547, 0.94852488379428634)\n",
      "Epoch:  132\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99999881, 0.99999881, 0.99999881, 0.99999881, 0.99999881, 0.99999881, 0.99999881, 0.99999881, 0.99999881]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000154, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000531, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000051, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0264470902032\n",
      "Train loss/acc:  (1.2856095608686985e-05, 0.99997069900387281) Test loss/acc:  (0.086043025208402429, 0.94821757092824654)\n",
      "Epoch:  133\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99999887, 0.99999887, 0.99999887, 0.99999887, 0.99999887, 0.99999887, 0.99999887, 0.99999887, 0.99999887]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000934, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000060, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000246, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000191, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.001115, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0264263204415\n",
      "Train loss/acc:  (1.4068285282913156e-05, 0.99997069900387281) Test loss/acc:  (0.086993929329565789, 0.94906268382849102)\n",
      "Epoch:  134\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99999893, 0.99999893, 0.99999893, 0.99999893, 0.99999893, 0.99999893, 0.99999893, 0.99999893, 0.99999893]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.002621, 0.99\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000032, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000006, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000018, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.026409610934\n",
      "Train loss/acc:  (1.3242359263861766e-05, 0.99997069900387281) Test loss/acc:  (0.082705055605608702, 0.95086815229719523)\n",
      "Epoch:  135\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99999899, 0.99999899, 0.99999899, 0.99999899, 0.99999899, 0.99999899, 0.99999899, 0.99999899, 0.99999899]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000001, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000417, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000002, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000094, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0263874356996\n",
      "Train loss/acc:  (1.3958030565531664e-05, 0.99997069900387281) Test loss/acc:  (0.086094674575883837, 0.95002304031281803)\n",
      "Epoch:  136\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99999905, 0.99999905, 0.99999905, 0.99999905, 0.99999905, 0.99999905, 0.99999905, 0.99999905, 0.99999905]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000010, 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000008, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000001, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000328, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000093, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000051, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0263515180666\n",
      "Train loss/acc:  (1.7790372418602319e-05, 0.99997069900387281) Test loss/acc:  (0.086348795854631344, 0.94952365450135168)\n",
      "Epoch:  137\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99999911, 0.99999911, 0.99999911, 0.99999911, 0.99999911, 0.99999911, 0.99999911, 0.99999911, 0.99999911]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000001, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000032, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000009, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000007, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000229, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000458, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0263126333247\n",
      "Train loss/acc:  (2.3721997087947054e-05, 0.99997069900387281) Test loss/acc:  (0.087588235184083194, 0.9490242696057527)\n",
      "Epoch:  138\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99999917, 0.99999917, 0.99999917, 0.99999917, 0.99999917, 0.99999917, 0.99999917, 0.99999917, 0.99999917]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000001, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000303, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000289, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000004, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000483, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000199, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000174, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.02630466898\n",
      "Train loss/acc:  (1.6216679936035526e-05, 0.99997069900387281) Test loss/acc:  (0.086695047096562811, 0.95013828206516582)\n",
      "Epoch:  139\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99999923, 0.99999923, 0.99999923, 0.99999923, 0.99999923, 0.99999923, 0.99999923, 0.99999923, 0.99999923]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000837, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000424, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000135, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0262871786543\n",
      "Train loss/acc:  (1.7520124143182904e-05, 0.99997069900387281) Test loss/acc:  (0.088172771384654486, 0.95002304122868531)\n",
      "Epoch:  140\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99999928, 0.99999928, 0.99999928, 0.99999928, 0.99999928, 0.99999928, 0.99999928, 0.99999928, 0.99999928]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000105, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000012, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000236, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000019, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000091, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000022, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0262789019823\n",
      "Train loss/acc:  (1.3434342108507029e-05, 0.99997069900387281) Test loss/acc:  (0.08782740976471401, 0.94983096828325875)\n",
      "Epoch:  141\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.99999934, 0.99999934, 0.99999934, 0.99999934, 0.99999934, 0.99999934, 0.99999934, 0.99999934, 0.99999934]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000862, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000045, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000213, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000014, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000613, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000116, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0262709376376\n",
      "Train loss/acc:  (1.3337380628222322e-05, 0.99997069900387281) Test loss/acc:  (0.087920099680014893, 0.94983096919912613)\n",
      "Epoch:  142\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.001176, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000002, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000001, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000124, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0262642226019\n",
      "Train loss/acc:  (1.2523678687936863e-05, 0.99997069900387281) Test loss/acc:  (0.089183670081102048, 0.94894744207614323)\n",
      "Epoch:  143\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000109, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000085, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000014, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.001508, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000395, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000076, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0262531349847\n",
      "Train loss/acc:  (1.4136937175897414e-05, 0.99997069900387281) Test loss/acc:  (0.086785114550597842, 0.94948524027861325)\n",
      "Epoch:  144\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000054, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000003, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000134, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000003, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000007, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0262482939124\n",
      "Train loss/acc:  (1.311429190416638e-05, 0.99997069900387281) Test loss/acc:  (0.087723981046427521, 0.94898585629888155)\n",
      "Epoch:  145\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000002, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000580, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000005, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000044, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000091, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000131, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000043, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0262437651674\n",
      "Train loss/acc:  (1.2324750847114439e-05, 0.99997069900387281) Test loss/acc:  (0.088027699706822948, 0.9489474429920105)\n",
      "Epoch:  146\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000438, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000001, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000223, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000001, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0262392364224\n",
      "Train loss/acc:  (1.4138937298582116e-05, 0.99997069900387281) Test loss/acc:  (0.089714771691886061, 0.94963889808543411)\n",
      "Epoch:  147\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000041, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000008, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000019, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000168, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000448, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000193, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0262337706956\n",
      "Train loss/acc:  (1.172645658340267e-05, 0.9999853495019364) Test loss/acc:  (0.087260982789873126, 0.9495620687240901)\n",
      "Epoch:  148\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000155, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000088, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000134, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000107, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0262211214422\n",
      "Train loss/acc:  (1.17364609562561e-05, 0.99997069900387281) Test loss/acc:  (0.087067149866878357, 0.9501382829810332)\n",
      "Epoch:  149\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.001086, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000015, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000023, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.002170, 0.99\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000056, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0262003516805\n",
      "Train loss/acc:  (1.1409357145127512e-05, 0.99997069900387281) Test loss/acc:  (0.086676589295167319, 0.95002304031281803)\n",
      "Epoch:  150\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000014, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000018, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000034, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000168, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000019, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000082, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0261906695359\n",
      "Train loss/acc:  (1.3832148581084442e-05, 0.99997069900387281) Test loss/acc:  (0.0882938174197717, 0.94990779856047014)\n",
      "Epoch:  151\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000441, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000031, 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000023, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000289, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000008, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0261584998298\n",
      "Train loss/acc:  (1.257356225392143e-05, 0.9999853495019364) Test loss/acc:  (0.088983666854690169, 0.94944682605587494)\n",
      "Epoch:  152\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000017, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000103, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000107, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000131, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000347, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000149, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0261488176852\n",
      "Train loss/acc:  (1.3773172992136717e-05, 0.99997069900387281) Test loss/acc:  (0.089175449269832313, 0.94983096923576082)\n",
      "Epoch:  153\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000075, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000013, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000022, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000819, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0261374177408\n",
      "Train loss/acc:  (1.1765997589932583e-05, 0.9999853495019364) Test loss/acc:  (0.088122874616285221, 0.9496388990013015)\n",
      "Epoch:  154\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000063, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000060, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000064, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000436, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0261272671054\n",
      "Train loss/acc:  (1.2465835294530867e-05, 0.9999853495019364) Test loss/acc:  (0.090577886971635324, 0.94852488287841896)\n",
      "Epoch:  155\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000012, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000117, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.003359, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000152, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000014, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000020, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0261107137615\n",
      "Train loss/acc:  (1.1989005549839219e-05, 0.99997069900387281) Test loss/acc:  (0.087918657599991276, 0.9507144972379763)\n",
      "Epoch:  156\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000016, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000807, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000117, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000096, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0261021247622\n",
      "Train loss/acc:  (1.177078906080047e-05, 0.99997069900387281) Test loss/acc:  (0.087889441804755442, 0.95006145453555646)\n",
      "Epoch:  157\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000604, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000003, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.026093535763\n",
      "Train loss/acc:  (1.31881553040937e-05, 0.99997069900387281) Test loss/acc:  (0.089445297346984448, 0.95052242612428439)\n",
      "Epoch:  158\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000204, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000005, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000088, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000468, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000970, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0260715166923\n",
      "Train loss/acc:  (1.2758300012627245e-05, 0.99997069900387281) Test loss/acc:  (0.089971864798644899, 0.9497925549763877)\n",
      "Epoch:  159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000399, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000165, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000009, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000023, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.026051840076\n",
      "Train loss/acc:  (1.2046472795942274e-05, 0.9999853495019364) Test loss/acc:  (0.090072133957872599, 0.95025352656511564)\n",
      "Epoch:  160\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000084, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000005, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000052, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.026041064786\n",
      "Train loss/acc:  (1.3404524753238276e-05, 0.99997069900387281) Test loss/acc:  (0.091610420559382399, 0.9498309701149934)\n",
      "Epoch:  161\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000002, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000100, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000003, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000738, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000017, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.026030757987\n",
      "Train loss/acc:  (1.2447570413579512e-05, 0.9999853495019364) Test loss/acc:  (0.09191043232810886, 0.9497925549763877)\n",
      "Epoch:  162\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000261, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000002, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000001, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0260170155883\n",
      "Train loss/acc:  (1.4513598060509927e-05, 0.9999853495019364) Test loss/acc:  (0.09206756816623983, 0.94975414166951666)\n",
      "Epoch:  163\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000158, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000107, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000047, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000101, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0260067087892\n",
      "Train loss/acc:  (1.4372202702534065e-05, 0.9999853495019364) Test loss/acc:  (0.093255016831400653, 0.94906268291262375)\n",
      "Epoch:  164\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000025, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000709, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000008, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000016, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0259967143174\n",
      "Train loss/acc:  (1.2656983192868387e-05, 0.9999853495019364) Test loss/acc:  (0.092221484149187419, 0.95002304031281803)\n",
      "Epoch:  165\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000023, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000093, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000131, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000150, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0259826595914\n",
      "Train loss/acc:  (1.1600317975674898e-05, 0.9999853495019364) Test loss/acc:  (0.092415779898860156, 0.95059925273802648)\n",
      "Epoch:  166\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000281, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000170, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000078, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000006, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000058, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000158, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000032, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0259714158106\n",
      "Train loss/acc:  (1.2578737915250511e-05, 0.99997069900387281) Test loss/acc:  (0.093618399422952345, 0.94998462517421234)\n",
      "Epoch:  167\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000058, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000080, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000005, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000117, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000064, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0258717834198\n",
      "Train loss/acc:  (1.2301031023281561e-05, 0.99997069900387281) Test loss/acc:  (0.092477108454348922, 0.94975414075364928)\n",
      "Epoch:  168\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000007, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0258608519663\n",
      "Train loss/acc:  (1.3886403105460248e-05, 0.99997069900387281) Test loss/acc:  (0.093478930265755475, 0.94986938250599717)\n",
      "Epoch:  169\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000289, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.001210, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000016, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000010, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000027, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0258499205127\n",
      "Train loss/acc:  (1.273336421893562e-05, 0.9999853495019364) Test loss/acc:  (0.094116595849055934, 0.9499077967287356)\n",
      "Epoch:  170\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.001084, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000003, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000151, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000030, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000057, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0258321178598\n",
      "Train loss/acc:  (1.4604007879465053e-05, 0.9999853495019364) Test loss/acc:  (0.095453052268064165, 0.94948523936274598)\n",
      "Epoch:  171\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.001047, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000011, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000210, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0258182192975\n",
      "Train loss/acc:  (1.242728425793665e-05, 0.99997069900387281) Test loss/acc:  (0.096079886548069995, 0.94829439937372328)\n",
      "Epoch:  172\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000170, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000005, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.004388, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000511, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0257947947542\n",
      "Train loss/acc:  (1.1740130925138164e-05, 0.99997069900387281) Test loss/acc:  (0.093892118202656347, 0.94844805721717884)\n",
      "Epoch:  173\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000049, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000005, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000040, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000027, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0257863619186\n",
      "Train loss/acc:  (1.2111001818879314e-05, 0.99997069900387281) Test loss/acc:  (0.092939764685979198, 0.94975413983778201)\n",
      "Epoch:  174\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000245, 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000560, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000096, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000082, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000280, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000036, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000013, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000022, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0257746496469\n",
      "Train loss/acc:  (1.3075809399720554e-05, 0.9999853495019364) Test loss/acc:  (0.095005149385801985, 0.94890902785340481)\n",
      "Epoch:  175\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000007, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000161, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000008, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000045, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.025765123666\n",
      "Train loss/acc:  (1.3461375846671438e-05, 0.99997069900387281) Test loss/acc:  (0.09396967959041308, 0.9498309701149934)\n",
      "Epoch:  176\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000137, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000176, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000169, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000013, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.014962, 0.99\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0257493511402\n",
      "Train loss/acc:  (1.8711290300412443e-05, 0.9999853495019364) Test loss/acc:  (0.096220062341547924, 0.94837122873506741)\n",
      "Epoch:  177\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000020, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000042, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.002275, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.001360, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0257059376532\n",
      "Train loss/acc:  (1.3982688356421482e-05, 0.99997069900387281) Test loss/acc:  (0.097013714379266355, 0.94867854343284175)\n",
      "Epoch:  178\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000011, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000267, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000002, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000102, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000136, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0256842309098\n",
      "Train loss/acc:  (1.3514272814135328e-05, 0.9999853495019364) Test loss/acc:  (0.099542453292054342, 0.94902426868988532)\n",
      "Epoch:  179\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000114, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000058, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000009, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000002, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0256725186381\n",
      "Train loss/acc:  (1.4898416557972917e-05, 0.99997069900387281) Test loss/acc:  (0.096940464815828936, 0.94933158342429447)\n",
      "Epoch:  180\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000117, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000011, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000030, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000392, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000099, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000305, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0256639296389\n",
      "Train loss/acc:  (1.3282463095809742e-05, 0.9999853495019364) Test loss/acc:  (0.097053400645537399, 0.94867854251697448)\n",
      "Epoch:  181\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000303, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000002, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000086, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000412, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000818, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000185, 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity fraction (ratio of non-zero weights):  0.0256520612036\n",
      "Train loss/acc:  (1.2791233724876126e-05, 0.99997069900387281) Test loss/acc:  (0.097433752748375665, 0.94971572653091096)\n",
      "Epoch:  182\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000021, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000012, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000400, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0256423790591\n",
      "Train loss/acc:  (1.2380508828941761e-05, 0.99997069900387281) Test loss/acc:  (0.098717982306636837, 0.94921634163531188)\n",
      "Epoch:  183\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000002, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000008, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000041, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000186, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000005, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0256350393688\n",
      "Train loss/acc:  (1.1854338340677771e-05, 0.99997069900387281) Test loss/acc:  (0.097730283605389309, 0.94906268478099309)\n",
      "Epoch:  184\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000028, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000023, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000061, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000022, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0256212969701\n",
      "Train loss/acc:  (1.2817135222893629e-05, 0.9999853495019364) Test loss/acc:  (0.095742035482007812, 0.94956206963995737)\n",
      "Epoch:  185\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000002, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000058, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0256069299169\n",
      "Train loss/acc:  (1.2862372752013497e-05, 0.99997069900387281) Test loss/acc:  (0.096436915919184685, 0.94948524119448063)\n",
      "Epoch:  186\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000004, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000741, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000007, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000011, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000008, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0255997463903\n",
      "Train loss/acc:  (1.1880285139777083e-05, 0.9999853495019364) Test loss/acc:  (0.096972573984737187, 0.94852488471015362)\n",
      "Epoch:  187\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000003, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000013, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000005, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000003, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0255582068668\n",
      "Train loss/acc:  (1.4248431080380959e-05, 0.99997069900387281) Test loss/acc:  (0.09843590753593727, 0.9490626847443584)\n",
      "Epoch:  188\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000433, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000152, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000358, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0255510233402\n",
      "Train loss/acc:  (1.2821081208322735e-05, 0.99997069900387281) Test loss/acc:  (0.096097214455408919, 0.9501382829810332)\n",
      "Epoch:  189\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000108, 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000172, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000058, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000068, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000105, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000144, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0255408727048\n",
      "Train loss/acc:  (1.1976485225847876e-05, 0.99997069900387281) Test loss/acc:  (0.09783834940224391, 0.94879378426932237)\n",
      "Epoch:  190\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000016, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000174, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000454, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000015, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.025515574198\n",
      "Train loss/acc:  (1.2536447998148681e-05, 0.99997069900387281) Test loss/acc:  (0.10043072596320582, 0.94802550076705661)\n",
      "Epoch:  191\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000031, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000008, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000230, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000225, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0254785634196\n",
      "Train loss/acc:  (1.3375720773024431e-05, 0.99997069900387281) Test loss/acc:  (0.099883176792772477, 0.94771818603264746)\n",
      "Epoch:  192\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.003080, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.001447, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000009, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000026, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0254606046031\n",
      "Train loss/acc:  (1.2365021584244968e-05, 0.9999853495019364) Test loss/acc:  (0.10084517983594919, 0.94702672819162192)\n",
      "Epoch:  193\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000002, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000395, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000784, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000044, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0254479553497\n",
      "Train loss/acc:  (1.1334214723083601e-05, 0.9999853495019364) Test loss/acc:  (0.10017201920356499, 0.94802550073042191)\n",
      "Epoch:  194\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000251, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000404, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000252, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000054, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.001377, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000005, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0254276540788\n",
      "Train loss/acc:  (1.2327708612080642e-05, 0.99997069900387281) Test loss/acc:  (0.10084800082748296, 0.94840964295780583)\n",
      "Epoch:  195\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000259, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000068, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000072, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000120, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0254076651352\n",
      "Train loss/acc:  (1.2188834410803696e-05, 0.9999853495019364) Test loss/acc:  (0.10140486740917609, 0.94860171407149774)\n",
      "Epoch:  196\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000001, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000002, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000011, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000652, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.002025, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000001, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0253995446269\n",
      "Train loss/acc:  (1.1538201169566579e-05, 0.99997069900387281) Test loss/acc:  (0.099658782996315129, 0.94933158430352704)\n",
      "Epoch:  197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000546, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000501, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000092, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.025394547391\n",
      "Train loss/acc:  (1.2085080365732002e-05, 0.99997069900387281) Test loss/acc:  (0.10063782680754509, 0.94967731413990719)\n",
      "Epoch:  198\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000009, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000551, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000008, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000007, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000027, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0253739337929\n",
      "Train loss/acc:  (1.3688454556522136e-05, 0.99997069900387281) Test loss/acc:  (0.098851439603172206, 0.94910109900373141)\n",
      "Epoch:  199\n",
      "========= Begin epoch =========\n",
      "batch_size = 100\n",
      "EMA rates:\n",
      "[0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994, 0.9999994]\n",
      "rho:\n",
      "[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "Iter: 0 of 682 || Estimated train loss/acc: 0.000005, 1.00\n",
      "Iter: 68 of 682 || Estimated train loss/acc: 0.000022, 1.00\n",
      "Iter: 136 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 204 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 272 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 340 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 408 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 476 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 544 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 612 of 682 || Estimated train loss/acc: 0.000000, 1.00\n",
      "Iter: 680 of 682 || Estimated train loss/acc: 0.000009, 1.00\n",
      "Sparsity fraction (ratio of non-zero weights):  0.0253622215212\n",
      "Train loss/acc:  (1.1567930216535579e-05, 0.99997069900387281) Test loss/acc:  (0.098271599667949336, 0.94910109808786414)\n"
     ]
    }
   ],
   "source": [
    "losses_and_accs_train = []\n",
    "losses_and_accs_valid = []\n",
    "losses_and_accs_test = []\n",
    "sparsity_fracs = []\n",
    "\n",
    "n_epochs = 200\n",
    "\n",
    "for t in range(n_epochs):    \n",
    "    print('Epoch: ', t)\n",
    "    opt.train_epoch(batch_size=100, ema_decay=0.95, n_output=10, verbose=True)\n",
    "\n",
    "    losses_and_accs_train.append(\n",
    "        opt.loss_and_accuracy((x_train, y_train), max_batch=400, inference=True))\n",
    "    losses_and_accs_test.append(\n",
    "        opt.loss_and_accuracy((x_test, y_test), max_batch=400, inference=True))\n",
    "    losses_and_accs_valid.append(\n",
    "        opt.loss_and_accuracy((x_validate, y_validate), max_batch=400, inference=True))\n",
    "    sparsity_fracs.append(utils.get_sparsity_frac(nn, opt))\n",
    "\n",
    "    print('Train loss/acc: ', losses_and_accs_train[-1],\n",
    "          'Test loss/acc: ', losses_and_accs_test[-1])\n",
    "    \n",
    "losses_and_accs_train = np.asarray(losses_and_accs_train)\n",
    "losses_and_accs_valid = np.asarray(losses_and_accs_valid)\n",
    "losses_and_accs_test = np.asarray(losses_and_accs_test)\n",
    "sparsity_fracs = np.asarray(sparsity_fracs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  (1.1567930216535579e-05, 0.99997069900387281)\n",
      "Valid:  (0.11807159632444382, 0.94599999189376827)\n",
      "Test:  (0.098271599667949336, 0.94910109808786414)\n"
     ]
    }
   ],
   "source": [
    "print('Train: ', opt.loss_and_accuracy((x_train, y_train), inference=True,\n",
    "                                       max_batch=400))\n",
    "print('Valid: ', opt.loss_and_accuracy((x_validate, y_validate), inference=True,\n",
    "                                      max_batch=400))\n",
    "print('Test: ', opt.loss_and_accuracy((x_test, y_test), inference=True,\n",
    "                                     max_batch=400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch:  79\n",
      "Train acc:  0.999970699004\n",
      "Valid acc:  0.950199990273\n",
      "Test acc:  0.952366308852\n"
     ]
    }
   ],
   "source": [
    "best_epoch = np.argmax(losses_and_accs_valid[:,1]) + 1\n",
    "print('Best epoch: ', best_epoch)\n",
    "print('Train acc: ', losses_and_accs_train[best_epoch-1, 1])\n",
    "print('Valid acc: ', losses_and_accs_valid[best_epoch-1, 1])\n",
    "print('Test acc: ', losses_and_accs_test[best_epoch-1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results:  [  1.15679302e-05   9.99970699e-01   1.18071596e-01   9.45999992e-01\n",
      "   9.82715997e-02   9.49101098e-01]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f226408ceb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses_and_accs = np.concatenate(\n",
    "    [np.asarray(losses_and_accs_train),\n",
    "     np.asarray(losses_and_accs_valid),\n",
    "     np.asarray(losses_and_accs_test)], axis=1)\n",
    "\n",
    "# Plot\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,4))\n",
    "ax1.semilogy(losses_and_accs[:,0], '-o', label='Train loss')\n",
    "ax1.semilogy(losses_and_accs[:,2], '-o', label='Valid loss')\n",
    "ax1.semilogy(losses_and_accs[:,4], '-o', label='Test loss')\n",
    "\n",
    "ax2.plot(losses_and_accs[:,1], '-o', label='Train acc')\n",
    "ax2.plot(losses_and_accs[:,3], '-o', label='Valid acc')\n",
    "ax2.plot(losses_and_accs[:,5], '-o', label='Test acc')\n",
    "\n",
    "for ax in [ax1,ax2]:\n",
    "    ax.legend()\n",
    "\n",
    "ax1.set_ylim(1e-5,1)\n",
    "ax2.set_ylim(0.1,1)\n",
    "    \n",
    "print('Final results: ', losses_and_accs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final sparsity fraction:  0.0253622215212\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f225400ae80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot sparsity fracs\n",
    "plt.plot(sparsity_fracs)\n",
    "print('Final sparsity fraction: ', sparsity_fracs[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
